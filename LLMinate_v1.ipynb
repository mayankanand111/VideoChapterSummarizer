{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "it8QuBzKiqxO",
    "outputId": "a73f4378-9650-4cb1-e215-f0552840aca4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2023.10.13)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
      "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
      "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.47.0)\n",
      "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (3.19.0)\n",
      "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (12.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2023.7.22)\n",
      "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.1.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "pip install -U yt-dlp tiktoken openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "import openai\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ],
   "metadata": {
    "id": "PYTQzeMfi78_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pip install youtube-dl\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FnJJl1ujlP8j",
    "outputId": "91636bdb-9693-4b29-e346-91007dd2725e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: youtube-dl in /usr/local/lib/python3.10/dist-packages (2021.12.17)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "playlist_url = \"https://www.youtube.com/playlist?list=PLLssT5z_DsK_gyrQ_biidwvPYCRNGI3iv\""
   ],
   "metadata": {
    "id": "8FNT3ID9G2cD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import youtube_dl\n",
    "\n",
    "def get_playlist_videos(playlist_url):\n",
    "    ydl_opts = {\n",
    "        'quiet': True,\n",
    "        'extract_flat': True,\n",
    "        'force_generic_extractor': True,\n",
    "    }\n",
    "\n",
    "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "        playlist_info = ydl.extract_info(playlist_url, download=False)\n",
    "        videos = playlist_info['entries']\n",
    "\n",
    "        if videos:\n",
    "            base_url = \"https://www.youtube.com/watch?v=\"\n",
    "            return {video['id']:base_url + video['id'] for video in videos}\n",
    "        else:\n",
    "            return {}"
   ],
   "metadata": {
    "id": "Njzn_iyOlUTX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "video_list_dict = get_playlist_videos(playlist_url)"
   ],
   "metadata": {
    "id": "0_Fc2UG_GpSK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "video_list_dict\n",
    "#!apt-get install jq"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UlCpiA1djSTI",
    "outputId": "28467621-eea6-4dfa-c1d9-719938a1b4ee"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'OVwEeSsSCHE': 'https://www.youtube.com/watch?v=OVwEeSsSCHE',\n",
       " 'jNBYZbDWyQk': 'https://www.youtube.com/watch?v=jNBYZbDWyQk',\n",
       " 'VA9niXgGOsQ': 'https://www.youtube.com/watch?v=VA9niXgGOsQ',\n",
       " 'mnTJezQOIDU': 'https://www.youtube.com/watch?v=mnTJezQOIDU',\n",
       " 'nrkpEx7tA2Y': 'https://www.youtube.com/watch?v=nrkpEx7tA2Y',\n",
       " '6cHupvcxA38': 'https://www.youtube.com/watch?v=6cHupvcxA38',\n",
       " '5tHN6Y70d5Y': 'https://www.youtube.com/watch?v=5tHN6Y70d5Y',\n",
       " 'TNhgCkYDc8M': 'https://www.youtube.com/watch?v=TNhgCkYDc8M',\n",
       " '92hto4KwlGI': 'https://www.youtube.com/watch?v=92hto4KwlGI',\n",
       " '16qJwiH-FdE': 'https://www.youtube.com/watch?v=16qJwiH-FdE',\n",
       " '6gZjRI_gnGc': 'https://www.youtube.com/watch?v=6gZjRI_gnGc',\n",
       " 'tafPPLVuB2s': 'https://www.youtube.com/watch?v=tafPPLVuB2s',\n",
       " 'MVT-bHFqZ9o': 'https://www.youtube.com/watch?v=MVT-bHFqZ9o',\n",
       " 'VCT1N0EsGj0': 'https://www.youtube.com/watch?v=VCT1N0EsGj0',\n",
       " '7UknKXkcbZA': 'https://www.youtube.com/watch?v=7UknKXkcbZA',\n",
       " '_LzxJ1LbSl4': 'https://www.youtube.com/watch?v=_LzxJ1LbSl4',\n",
       " 'QJw5CN_0zxU': 'https://www.youtube.com/watch?v=QJw5CN_0zxU',\n",
       " 'PHP8beSz5o4': 'https://www.youtube.com/watch?v=PHP8beSz5o4',\n",
       " 'wqUgMFMnlzI': 'https://www.youtube.com/watch?v=wqUgMFMnlzI',\n",
       " 'qgjzwJwKiBc': 'https://www.youtube.com/watch?v=qgjzwJwKiBc',\n",
       " 'XSmoVWhM8G4': 'https://www.youtube.com/watch?v=XSmoVWhM8G4',\n",
       " 'ARzsyifxGEI': 'https://www.youtube.com/watch?v=ARzsyifxGEI',\n",
       " 'w7qvEv1EKZ0': 'https://www.youtube.com/watch?v=w7qvEv1EKZ0',\n",
       " '924oc7aLH-g': 'https://www.youtube.com/watch?v=924oc7aLH-g',\n",
       " 'EANflep-cog': 'https://www.youtube.com/watch?v=EANflep-cog',\n",
       " 'iNucJB-0vYs': 'https://www.youtube.com/watch?v=iNucJB-0vYs',\n",
       " 'z2rTn8Evav8': 'https://www.youtube.com/watch?v=z2rTn8Evav8',\n",
       " 'Gkdq3dHYQtk': 'https://www.youtube.com/watch?v=Gkdq3dHYQtk',\n",
       " 'XhZahXzEuNo': 'https://www.youtube.com/watch?v=XhZahXzEuNo',\n",
       " 'V0-2pV8vQ84': 'https://www.youtube.com/watch?v=V0-2pV8vQ84',\n",
       " '4gOdNtVNZtk': 'https://www.youtube.com/watch?v=4gOdNtVNZtk',\n",
       " 'sGXOyI5I_Fw': 'https://www.youtube.com/watch?v=sGXOyI5I_Fw',\n",
       " 'WCngMib2mb4': 'https://www.youtube.com/watch?v=WCngMib2mb4',\n",
       " 'OtFAECd_IXQ': 'https://www.youtube.com/watch?v=OtFAECd_IXQ',\n",
       " 'XxQ4hgcKDlY': 'https://www.youtube.com/watch?v=XxQ4hgcKDlY',\n",
       " 'GhGBrxStXuA': 'https://www.youtube.com/watch?v=GhGBrxStXuA',\n",
       " '74Hj4By5kjg': 'https://www.youtube.com/watch?v=74Hj4By5kjg',\n",
       " 'prXjoD9rEHo': 'https://www.youtube.com/watch?v=prXjoD9rEHo',\n",
       " 'MbpaeKYMXVk': 'https://www.youtube.com/watch?v=MbpaeKYMXVk',\n",
       " 'Ukb5yqeF1po': 'https://www.youtube.com/watch?v=Ukb5yqeF1po',\n",
       " 'pu2d_AFuwdQ': 'https://www.youtube.com/watch?v=pu2d_AFuwdQ',\n",
       " 'jN5uYO9qllc': 'https://www.youtube.com/watch?v=jN5uYO9qllc',\n",
       " 'PD2DmW9E_Q0': 'https://www.youtube.com/watch?v=PD2DmW9E_Q0',\n",
       " 'CzrAOBC8ts0': 'https://www.youtube.com/watch?v=CzrAOBC8ts0',\n",
       " 'kZ7JJOMt5Kw': 'https://www.youtube.com/watch?v=kZ7JJOMt5Kw',\n",
       " 'FxrTtRvYQWk': 'https://www.youtube.com/watch?v=FxrTtRvYQWk',\n",
       " '1A6Md5ZYyW0': 'https://www.youtube.com/watch?v=1A6Md5ZYyW0',\n",
       " 'RsC9xfHYYH0': 'https://www.youtube.com/watch?v=RsC9xfHYYH0',\n",
       " 'iCbVPfk_5CQ': 'https://www.youtube.com/watch?v=iCbVPfk_5CQ',\n",
       " 'Rs1XMS8NqB4': 'https://www.youtube.com/watch?v=Rs1XMS8NqB4',\n",
       " 'HJfhdksIqUE': 'https://www.youtube.com/watch?v=HJfhdksIqUE',\n",
       " 'GZTmqMSxAR4': 'https://www.youtube.com/watch?v=GZTmqMSxAR4',\n",
       " '4vBqFO9bPeg': 'https://www.youtube.com/watch?v=4vBqFO9bPeg',\n",
       " 'kytxEr0KK7Q': 'https://www.youtube.com/watch?v=kytxEr0KK7Q',\n",
       " '2k9XTr_jNfE': 'https://www.youtube.com/watch?v=2k9XTr_jNfE',\n",
       " 'CkZ9HA6KUnA': 'https://www.youtube.com/watch?v=CkZ9HA6KUnA',\n",
       " 'EZOpZzUKl48': 'https://www.youtube.com/watch?v=EZOpZzUKl48',\n",
       " 'iHaS6O1eox4': 'https://www.youtube.com/watch?v=iHaS6O1eox4',\n",
       " 'on5lto0rG48': 'https://www.youtube.com/watch?v=on5lto0rG48',\n",
       " 'lDFY8vQe6-g': 'https://www.youtube.com/watch?v=lDFY8vQe6-g',\n",
       " '1CgojqlHrcE': 'https://www.youtube.com/watch?v=1CgojqlHrcE',\n",
       " 'HacQtntlLcw': 'https://www.youtube.com/watch?v=HacQtntlLcw',\n",
       " 'FBkhbqrFyo4': 'https://www.youtube.com/watch?v=FBkhbqrFyo4',\n",
       " 'Y3beRvYSA90': 'https://www.youtube.com/watch?v=Y3beRvYSA90',\n",
       " 'QCBkbDpsheQ': 'https://www.youtube.com/watch?v=QCBkbDpsheQ',\n",
       " 'YPQjud6JaSE': 'https://www.youtube.com/watch?v=YPQjud6JaSE',\n",
       " 'SnbfQwJLNk8': 'https://www.youtube.com/watch?v=SnbfQwJLNk8',\n",
       " 'lgApksxm6VE': 'https://www.youtube.com/watch?v=lgApksxm6VE',\n",
       " 'PSOt7u8u23w': 'https://www.youtube.com/watch?v=PSOt7u8u23w',\n",
       " '6jhhIPdgkp0': 'https://www.youtube.com/watch?v=6jhhIPdgkp0',\n",
       " 'ZCNbjpcX0yg': 'https://www.youtube.com/watch?v=ZCNbjpcX0yg',\n",
       " '3BDc0H9C9dw': 'https://www.youtube.com/watch?v=3BDc0H9C9dw',\n",
       " 'j1ry6Pg7X14': 'https://www.youtube.com/watch?v=j1ry6Pg7X14',\n",
       " 'xjlvVfEbhz4': 'https://www.youtube.com/watch?v=xjlvVfEbhz4',\n",
       " 'kVuF-9BaDLs': 'https://www.youtube.com/watch?v=kVuF-9BaDLs',\n",
       " 'hh0tKskwyzg': 'https://www.youtube.com/watch?v=hh0tKskwyzg',\n",
       " 'i0cKa0di_lo': 'https://www.youtube.com/watch?v=i0cKa0di_lo',\n",
       " 'FOqMeBM3EIE': 'https://www.youtube.com/watch?v=FOqMeBM3EIE'}"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Install jq\n",
    "!apt-get install jq"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTABxwPEPYME",
    "outputId": "3b693a7e-06e2-4f1c-d55d-cadbd04e2537"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "jq is already the newest version (1.6-2.1ubuntu3).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pip install webvtt-py"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y081_OM91d5F",
    "outputId": "e1592dbc-7afc-44eb-ab94-debee3a82b4e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: webvtt-py in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
      "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from webvtt-py) (0.6.2)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def pre_preprocess_transcript(original_transcript):\n",
    "    # Define a regular expression pattern to match the time format with at least one or two digits for minutes\n",
    "    time_pattern = re.compile(r'^(\\d{2,}:\\d{2}:\\d{2},\\d{3}) --> (\\d{2}:\\d{2}:\\d{2})', re.MULTILINE)\n",
    "\n",
    "    # Replace the matched time format with the desired format in the expected output\n",
    "    formatted_transcript = re.sub(time_pattern, r'\\n\\1 --> \\2', original_transcript)\n",
    "\n",
    "    # Remove extra tabs and white spaces\n",
    "    formatted_transcript = re.sub(r' {2,}', ' ', formatted_transcript)\n",
    "\n",
    "    # Convert the formatted transcript to a Pandas DataFrame\n",
    "    df = pd.DataFrame({'transcript': formatted_transcript.split('\\n')})\n",
    "\n",
    "    # Remove lines with only digits\n",
    "    df = df[~df['transcript'].str.match(r'^\\d+$')]\n",
    "\n",
    "    # Remove duplicate lines and keep the last occurrence\n",
    "    df = df.drop_duplicates(keep='last')\n",
    "\n",
    "    # Remove the time frame for duplicate rows\n",
    "    df['transcript'] = df.apply(lambda row: re.sub(time_pattern, '', row['transcript']) if df[df.duplicated(subset='transcript')].index.isin([row.name]).any() else row['transcript'], axis=1)\n",
    "\n",
    "    # Concatenate the unique lines back into a formatted transcript\n",
    "    formatted_transcript = '\\n'.join(df['transcript'])\n",
    "\n",
    "    lines = formatted_transcript.strip().split('\\n')\n",
    "\n",
    "    # Extract timestamps and text content\n",
    "    timestamps = [line if re.match(r'\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}', line) else None for line in lines]\n",
    "    text_content = [line if not re.search(r'\\d+:\\d+:\\d+,\\d+', line) else None for line in lines]\n",
    "\n",
    "    for index, line in enumerate(text_content):\n",
    "        if line is not None:\n",
    "            text_content[index-1] = timestamps[index-1]\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(text_content)\n",
    "\n",
    "    # Drop rows without timestamps\n",
    "    df_cleaned = df.dropna().reset_index(drop=True)\n",
    "    cleaned = '\\n'.join(df_cleaned[0].astype(str))\n",
    "    return cleaned.strip()\n"
   ],
   "metadata": {
    "id": "bBi81hIROtb3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_and_save_transcripts(transcripts_folder):\n",
    "    # Iterate through all .srt files in the transcripts folder\n",
    "    for filename in os.listdir(transcripts_folder):\n",
    "        if filename.endswith(\".srt\"):\n",
    "            file_path = os.path.join(transcripts_folder, filename)\n",
    "\n",
    "            # Read the content of the .srt file\n",
    "            with open(file_path, 'r', encoding='utf-8') as transcript_file:\n",
    "                transcript_text = transcript_file.read()\n",
    "\n",
    "            # Preprocess the transcript text\n",
    "            processed_transcript_text = pre_preprocess_transcript(transcript_text)\n",
    "\n",
    "            # Save the preprocessed transcript back to the file\n",
    "            with open(file_path, 'w', encoding='utf-8') as transcript_file:\n",
    "                transcript_file.write(processed_transcript_text)"
   ],
   "metadata": {
    "id": "yb0VodoPQt7a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def get_youtube_chapters_and_transcript(video_link):\n",
    "    ## Create the bash script content to get chapters\n",
    "    chapters_script = f'yt-dlp --dump-json \"{video_link}\" | jq --raw-output \\'.chapters[] | \"\\(.start_time / 60 | floor)min - \\(.title)\"\\''\n",
    "\n",
    "    # Run the chapters script directly in the shell\n",
    "    chapters_result = subprocess.run(chapters_script, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    # Check if there was an error in getting chapters\n",
    "    if chapters_result.returncode != 0:\n",
    "        print(f\"Error getting chapters: {chapters_result.stderr}\")\n",
    "        return None\n",
    "\n",
    "    # Parse the output into a list of chapters\n",
    "    chapters = [line.strip() for line in chapters_result.stdout.split('\\n') if line.strip()]\n",
    "\n",
    "    # Create folders if they don't exist\n",
    "    transcripts_folder = '/content/transcripts'\n",
    "\n",
    "    os.makedirs(transcripts_folder, exist_ok=True)\n",
    "\n",
    "    # Set a working directory for the subprocess to avoid getcwd() errors\n",
    "    chapters_folder = '/content/chapters'\n",
    "    working_directory = '/content/transcripts'\n",
    "\n",
    "    os.makedirs(chapters_folder, exist_ok=True)\n",
    "\n",
    "    # Create the bash script content to get transcript\n",
    "    transcript_script = f'yt-dlp --write-auto-sub --skip-download --sub-lang en --convert-subs srt \"{video_link}\"'\n",
    "\n",
    "    # Run the transcript script directly in the shell with the specified working directory\n",
    "    transcript_result = subprocess.run(transcript_script, shell=True, capture_output=True, text=True, cwd=working_directory)\n",
    "\n",
    "    # Check if there was an error in getting the transcript\n",
    "    if transcript_result.returncode != 0:\n",
    "        print(f\"Error getting transcript: {transcript_result.stderr}\")\n",
    "        return None\n",
    "\n",
    "    # Extract the transcript text from the subtitle file\n",
    "    transcript_text = transcript_result.stdout\n",
    "\n",
    "    # Save chapters and transcript files\n",
    "    video_id = video_link.split(\"=\")[-1]\n",
    "\n",
    "    chapters_filename = f'{chapters_folder}/chapters_{video_id}.txt'\n",
    "    transcript_filename = f'{transcripts_folder}/transcript_{video_id}.srt'\n",
    "\n",
    "    with open(chapters_filename, 'w', encoding='utf-8') as chapters_file:\n",
    "       chapters_file.write('\\n'.join(chapters))\n",
    "    with open(transcript_filename, 'w', encoding='utf-8') as transcript_file:\n",
    "         transcript_file.write(transcript_text)\n",
    "\n",
    "    preprocess_and_save_transcripts(transcripts_folder)\n",
    "    return chapters_filename, transcript_filename"
   ],
   "metadata": {
    "id": "v9ipNdK93vDe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for video_id, video_link in video_list_dict.items():\n",
    "    print(f\"Processing video: {video_id}\")\n",
    "    result = get_youtube_chapters_and_transcript(video_link)\n",
    "\n",
    "    if result:\n",
    "        chapters_filename, transcript_filename = result\n",
    "        print(f\"Chapters saved to: {chapters_filename}\")\n",
    "        print(f\"Transcript saved to: {transcript_filename}\")\n",
    "    else:\n",
    "        print(\"Error processing video.\")\n",
    "    print(\"-\" * 50)\n"
   ],
   "metadata": {
    "id": "oThirHBhAOBa",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "outputId": "6fcc381a-a9b9-4aac-e3bf-59edbb40f88e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing video: OVwEeSsSCHE\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-61-3bbeef4f1ec1>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mvideo_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvideo_link\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mvideo_list_dict\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Processing video: {video_id}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_youtube_chapters_and_transcript\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvideo_link\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-60-a05d5540a4fa>\u001B[0m in \u001B[0;36mget_youtube_chapters_and_transcript\u001B[0;34m(video_link)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0;31m# Run the chapters script directly in the shell\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0mchapters_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msubprocess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchapters_script\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshell\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcapture_output\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;31m# Check if there was an error in getting chapters\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/subprocess.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001B[0m\n\u001B[1;32m    503\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mPopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mpopenargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mprocess\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    504\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 505\u001B[0;31m             \u001B[0mstdout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstderr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprocess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcommunicate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    506\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mTimeoutExpired\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    507\u001B[0m             \u001B[0mprocess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkill\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/subprocess.py\u001B[0m in \u001B[0;36mcommunicate\u001B[0;34m(self, input, timeout)\u001B[0m\n\u001B[1;32m   1152\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1153\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1154\u001B[0;31m                 \u001B[0mstdout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstderr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_communicate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mendtime\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1155\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyboardInterrupt\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1156\u001B[0m                 \u001B[0;31m# https://bugs.python.org/issue25942\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/subprocess.py\u001B[0m in \u001B[0;36m_communicate\u001B[0;34m(self, input, endtime, orig_timeout)\u001B[0m\n\u001B[1;32m   2019\u001B[0m                             'failed to raise TimeoutExpired.')\n\u001B[1;32m   2020\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2021\u001B[0;31m                     \u001B[0mready\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mselector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2022\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_timeout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mendtime\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morig_timeout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstdout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstderr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2023\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/selectors.py\u001B[0m in \u001B[0;36mselect\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    414\u001B[0m         \u001B[0mready\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    415\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 416\u001B[0;31m             \u001B[0mfd_event_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_selector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpoll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    417\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mInterruptedError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    418\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "id": "p16Gu4ACNOav"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_num_tokens(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"Calculates the number of tokens in a text prompt\"\"\"\n",
    "\n",
    "    enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "    return len(enc.encode(prompt))\n",
    "\n",
    "\n",
    "def get_response(prompt_question,):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful research and\\\n",
    "            programming assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def load_transcription(transcription_file):\n",
    "    with open(transcription_file, \"r\") as f:\n",
    "        transcription_with_timestamp = f.read()\n",
    "\n",
    "    return transcription_with_timestamp\n"
   ],
   "metadata": {
    "id": "3W1NnKhVHzUP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "transcription_with_timestamp = load_transcription(\"/content/transcripts/Lecture 1.1 — Why do we need machine learning — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [OVwEeSsSCHE].en.srt\")\n",
    "display(Markdown(transcription_with_timestamp))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "j4IotZCqHzRa",
    "outputId": "181030d4-aabb-4c91-a46a-239b21ac056f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "00:00:03,780 --> 00:00:06,070\nhello welcome to the Coursera course on\n00:00:06,080 --> 00:00:09,020\nneural networks for machine learning\n00:00:09,030 --> 00:00:11,270\nbefore we get into the details of neural\n00:00:11,280 --> 00:00:13,120\nnetwork learning algorithms I want to\n00:00:13,130 --> 00:00:16,400\ntalk a little bit about machine learning\n00:00:16,410 --> 00:00:18,590\nwhy we need machine learning the kinds\n00:00:18,600 --> 00:00:22,279\nof things we use it for and show you\n00:00:22,289 --> 00:00:25,220\nsome examples of what it can do so the\n00:00:25,230 --> 00:00:27,410\nreason we need machine learning is that\n00:00:27,420 --> 00:00:30,109\nthe some problems where it's very hard\n00:00:30,119 --> 00:00:31,479\nto write the programs recognizing a\n00:00:31,489 --> 00:00:34,400\nthree-dimensional object for example\n00:00:34,410 --> 00:00:35,900\nwhen it's from a novel viewpoint in new\n00:00:35,910 --> 00:00:39,860\nlighting conditions in a cluttered scene\n00:00:39,870 --> 00:00:41,420\nis very hard to do we don't know what\n00:00:41,430 --> 00:00:44,540\nprograms right because we don't know how\n00:00:44,550 --> 00:00:46,279\nit's done in our brain and even if we\n00:00:46,289 --> 00:00:47,630\ndid know what programs right it might be\n00:00:47,640 --> 00:00:49,990\nthat it was a horrendously complicated\n00:00:50,000 --> 00:00:52,970\nprogram\n00:00:52,980 --> 00:00:55,580\nanother example is detecting a\n00:00:55,590 --> 00:00:58,099\nfraudulent credit card transaction where\n00:00:58,109 --> 00:01:00,260\nthere may not be any nice simple rules\n00:01:00,270 --> 00:01:02,090\nthat will tell you it's fraudulent you\n00:01:02,100 --> 00:01:05,719\nreally need to combine a very large\n00:01:05,729 --> 00:01:08,060\nnumber of not very reliable rules and\n00:01:08,070 --> 00:01:09,710\nalso those rules change over time\n00:01:09,720 --> 00:01:12,980\nbecause people change the tricks they\n00:01:12,990 --> 00:01:14,870\nuse for fraud so we need a complicated\n00:01:14,880 --> 00:01:19,399\nprogram that combines unreliable rules\n00:01:19,409 --> 00:01:21,890\nand that we can change easily the\n00:01:21,900 --> 00:01:24,140\nmachine learning approach is to say\n00:01:24,150 --> 00:01:26,780\ninstead of writing each program by hand\n00:01:26,790 --> 00:01:28,429\nfor each specific task for a particular\n00:01:28,439 --> 00:01:30,800\ntask we'll collect a lot of examples\n00:01:30,810 --> 00:01:34,010\nthat specify the correct output for a\n00:01:34,020 --> 00:01:36,859\ngiven input a machine learning algorithm\n00:01:36,869 --> 00:01:40,370\nthen takes these examples and produces a\n00:01:40,380 --> 00:01:42,590\nprogram that does the job the program\n00:01:42,600 --> 00:01:43,999\nproduced by the learning algorithm may\n00:01:44,009 --> 00:01:46,969\nlook very different from a typical\n00:01:46,979 --> 00:01:48,530\nhandwritten program for example it might\n00:01:48,540 --> 00:01:52,399\ncontain millions of numbers about how\n00:01:52,409 --> 00:01:54,319\nyou weight different kinds of errands if\n00:01:54,329 --> 00:01:55,940\nwe do it right the program should work\n00:01:55,950 --> 00:02:00,080\nfor new cases as well as ones it's\n00:02:00,090 --> 00:02:01,580\ntraining on and if the data changes we\n00:02:01,590 --> 00:02:04,280\nshould be able to change the program\n00:02:04,290 --> 00:02:09,109\nrelatively easily by retraining it on\n00:02:09,119 --> 00:02:11,059\nthe new data and now massive amounts of\n00:02:11,069 --> 00:02:12,350\ncomputation are cheaper than paying\n00:02:12,360 --> 00:02:13,650\nsomeone to write a program for a\n00:02:13,660 --> 00:02:16,530\nspecific task\n00:02:16,540 --> 00:02:19,050\nso we can afford big complicated machine\n00:02:19,060 --> 00:02:23,970\nlearning programs to produce the start\n00:02:23,980 --> 00:02:25,440\ntask specific systems for some examples\n00:02:25,450 --> 00:02:27,950\nof the things that are best done by\n00:02:27,960 --> 00:02:31,290\nusing a learning algorithm are\n00:02:31,300 --> 00:02:34,650\nrecognizing patterns so for example\n00:02:34,660 --> 00:02:37,580\nobjects in real scenes or the identities\n00:02:37,590 --> 00:02:42,210\nor expressions of people's faces or\n00:02:42,220 --> 00:02:45,540\nspoken words there's also recognizing\n00:02:45,550 --> 00:02:47,070\nanomalies so an unusual sequence of\n00:02:47,080 --> 00:02:50,640\ncredit-card transactions will be an\n00:02:50,650 --> 00:02:53,130\nanomaly another example of an anomaly\n00:02:53,140 --> 00:02:55,800\nwould be an unusual pattern of sensor\n00:02:55,810 --> 00:02:57,930\nreadings in a nuclear power plant and\n00:02:57,940 --> 00:02:59,370\nyou wouldn't really want to have to deal\n00:02:59,380 --> 00:03:00,990\nwith those by doing supervised learning\n00:03:01,000 --> 00:03:03,960\nwhere you look at the ones that blow up\n00:03:03,970 --> 00:03:05,610\nand see what what caused them to blow up\n00:03:05,620 --> 00:03:07,560\nyou'd really like to recognize that\n00:03:07,570 --> 00:03:09,750\nsomething funny is happening without\n00:03:09,760 --> 00:03:13,260\nhaving any supervision signal it's just\n00:03:13,270 --> 00:03:16,470\nnot behaving in its normal way and then\n00:03:16,480 --> 00:03:18,630\nthis prediction so typically predicting\n00:03:18,640 --> 00:03:21,210\nfuture stock prices or currency exchange\n00:03:21,220 --> 00:03:22,980\nrates or predicting which movies a\n00:03:22,990 --> 00:03:24,990\nperson will like from knowing which\n00:03:25,000 --> 00:03:29,640\nother movies they like and which movies\n00:03:29,650 --> 00:03:33,000\na lot of other people liked so in this\n00:03:33,010 --> 00:03:34,530\ncourse I knees a standard example for\n00:03:34,540 --> 00:03:38,310\nexplaining a lot of the machine learning\n00:03:38,320 --> 00:03:40,980\nalgorithms this is done in a lot of\n00:03:40,990 --> 00:03:44,820\nscience in genetics for example a lot of\n00:03:44,830 --> 00:03:46,500\ngenetics is done on fruit flies and the\n00:03:46,510 --> 00:03:49,199\nreason is they're convenient they breed\n00:03:49,209 --> 00:03:53,430\nfast and a lot is already known about\n00:03:53,440 --> 00:03:56,580\nthe genesis of fruit flies the emne\n00:03:56,590 --> 00:03:58,050\nstata basis of handwritten digits is the\n00:03:58,060 --> 00:04:03,240\nmachine learning equivalent of fruit\n00:04:03,250 --> 00:04:06,510\nflies it's publicly available we can get\n00:04:06,520 --> 00:04:08,190\nmachine learning out rooms to learn how\n00:04:08,200 --> 00:04:10,410\nto recognize these hundred and digits\n00:04:10,420 --> 00:04:13,740\nquite quickly so it's easy to try lots\n00:04:13,750 --> 00:04:15,630\nof variations and we know huge amounts\n00:04:15,640 --> 00:04:18,180\nabout how well different machine\n00:04:18,190 --> 00:04:19,380\nlearning methods do on any list and in\n00:04:19,390 --> 00:04:20,820\nparticular the different machine\n00:04:20,830 --> 00:04:23,010\nlearning methods were implemented by\n00:04:23,020 --> 00:04:26,340\npeople who believed in them so we can\n00:04:26,350 --> 00:04:27,330\nrely on those results so for all those\n00:04:27,340 --> 00:04:31,680\nreasons we're going to use\n00:04:31,690 --> 00:04:34,830\nas our standard task here's an example\n00:04:34,840 --> 00:04:36,600\nof some of the digits in n rest these\n00:04:36,610 --> 00:04:40,370\nare ones that were correctly recognized\n00:04:40,380 --> 00:04:42,390\nby neural net the first time it saw them\n00:04:42,400 --> 00:04:45,270\nbut they're ones where the neural net\n00:04:45,280 --> 00:04:49,250\nwasn't very confident and you can see\n00:04:49,260 --> 00:04:51,990\nwhy I've arranged these digits in\n00:04:52,000 --> 00:04:54,840\nstandard scanline order so zeros than\n00:04:54,850 --> 00:04:55,830\nones and twos and so on if you look at a\n00:04:55,840 --> 00:04:58,650\nbunch of two's\n00:04:58,660 --> 00:05:01,860\nlike the ones in the green rectangle you\n00:05:01,870 --> 00:05:04,290\ncan see that if you knew they were a\n00:05:04,300 --> 00:05:07,110\nhandwritten digit you'd probably guess\n00:05:07,120 --> 00:05:09,270\nthey were twos but it's very hard to say\n00:05:09,280 --> 00:05:10,740\nwhat it is that makes them twos there's\n00:05:10,750 --> 00:05:13,050\nnothing simple that they all have in\n00:05:13,060 --> 00:05:15,450\ncommon in particular if you try and\n00:05:15,460 --> 00:05:18,060\noverlay one on another you'll see it\n00:05:18,070 --> 00:05:20,670\ndoesn't fit and even if you skew it a\n00:05:20,680 --> 00:05:22,350\nbit it's very hard to make them overlay\n00:05:22,360 --> 00:05:25,500\non each other so template isn't going to\n00:05:25,510 --> 00:05:27,150\ndo the job and in particular template is\n00:05:27,160 --> 00:05:29,040\ngoing to be very hard to find that'll\n00:05:29,050 --> 00:05:31,110\nfit those twos in the green box and\n00:05:31,120 --> 00:05:34,950\nwon't also fit the things in the red\n00:05:34,960 --> 00:05:36,900\nboxes so that's one thing that makes\n00:05:36,910 --> 00:05:40,469\nrecognizing handwritten digits a good\n00:05:40,479 --> 00:05:41,610\ntask for machine learning now I don't\n00:05:41,620 --> 00:05:44,640\nwant you to think that's the only thing\n00:05:44,650 --> 00:05:46,290\nwe can do it's a relatively simple thing\n00:05:46,300 --> 00:05:49,560\nfor a machine learning system to do now\n00:05:49,570 --> 00:05:51,089\nand to motivate the rest of the course I\n00:05:51,099 --> 00:05:54,960\nwant to show you some examples are much\n00:05:54,970 --> 00:05:58,170\nmore difficult things so we now have\n00:05:58,180 --> 00:06:01,400\nneural nets with approaching 100 million\n00:06:01,410 --> 00:06:05,550\nparameters in them that can recognize a\n00:06:05,560 --> 00:06:07,440\nthousand different object classes in 1.3\n00:06:07,450 --> 00:06:11,339\nmillion high resolution training images\n00:06:11,349 --> 00:06:13,529\ngot from the web so there was a\n00:06:13,539 --> 00:06:16,200\ncompetition in 2010 and the best system\n00:06:16,210 --> 00:06:18,510\ngot 47 percent error rate if you look at\n00:06:18,520 --> 00:06:20,400\nhis first choice and 25 percent error\n00:06:20,410 --> 00:06:22,680\nrate if you say got it right if it was\n00:06:22,690 --> 00:06:26,730\nin its top 5 choices which isn't bad for\n00:06:26,740 --> 00:06:28,800\na thousand different objects Jitendra\n00:06:28,810 --> 00:06:31,020\nmalik who's an eminent neural net\n00:06:31,030 --> 00:06:34,409\nskeptic and a leading computer vision\n00:06:34,419 --> 00:06:36,029\nresearcher has said that this\n00:06:36,039 --> 00:06:37,589\ncompetition is a good test of whether\n00:06:37,599 --> 00:06:39,620\ndeep neural networks can work well for\n00:06:39,630 --> 00:06:43,310\nobject recognition\n00:06:43,320 --> 00:06:45,590\nand a very deep neural network can now\n00:06:45,600 --> 00:06:47,660\ndo considerably better than the thing\n00:06:47,670 --> 00:06:49,940\nthat won the competition it can get less\n00:06:49,950 --> 00:06:51,500\nthan 40 percent error for its first\n00:06:51,510 --> 00:06:53,960\nchoice and less than 20 percent our\n00:06:53,970 --> 00:06:55,910\nefforts top 5 choices I'll describe that\n00:06:55,920 --> 00:06:58,700\nin much more detail in lecture 5 here's\n00:06:58,710 --> 00:07:00,710\nsome examples of the kinds of images you\n00:07:00,720 --> 00:07:02,270\nhave to recognize these are images from\n00:07:02,280 --> 00:07:06,650\nthe test set that is never seen before\n00:07:06,660 --> 00:07:08,750\nand below the examples I'm showing you\n00:07:08,760 --> 00:07:11,090\nwhat the neural net thought the right\n00:07:11,100 --> 00:07:12,830\nanswer was where the length of the\n00:07:12,840 --> 00:07:16,640\nhorizontal bar is how confident it was\n00:07:16,650 --> 00:07:18,380\nand the correct answer is in red so if\n00:07:18,390 --> 00:07:21,290\nyou look in the middle a correctly\n00:07:21,300 --> 00:07:23,030\nidentified that as a snow plow but you\n00:07:23,040 --> 00:07:24,980\ncan see that his other choices were also\n00:07:24,990 --> 00:07:27,350\nfairly sensible it does look a little\n00:07:27,360 --> 00:07:29,030\nbit like a drilling platform and if you\n00:07:29,040 --> 00:07:30,890\nlook at its third choice a lifeboat\n00:07:30,900 --> 00:07:32,360\nit actually looks very like a lifeboat\n00:07:32,370 --> 00:07:33,800\nyou can see the flag on the front of the\n00:07:33,810 --> 00:07:35,720\nboat and the bridge of the boat and the\n00:07:35,730 --> 00:07:38,810\nflag at the back and the high surf in\n00:07:38,820 --> 00:07:40,190\nthe background so it's its errors tell\n00:07:40,200 --> 00:07:42,380\nyou a lot about how it's doing it and\n00:07:42,390 --> 00:07:44,800\nthey're very plausible errors if you\n00:07:44,810 --> 00:07:47,000\nlook on the left it gets it wrong\n00:07:47,010 --> 00:07:49,640\npossibly because the beak of the bird is\n00:07:49,650 --> 00:07:52,630\nmissing and cuz the feathers of the bird\n00:07:52,640 --> 00:07:55,700\nlook very like the wet fur of an otter\n00:07:55,710 --> 00:07:57,140\nbut he gets it in his top five and it\n00:07:57,150 --> 00:07:58,940\ndoes better than me I wouldn't know if\n00:07:58,950 --> 00:08:01,730\nthat was a quail or a roughed grouse or\n00:08:01,740 --> 00:08:05,180\na partridge if you look on the right he\n00:08:05,190 --> 00:08:07,370\ngets it completely wrong it a guillotine\n00:08:07,380 --> 00:08:09,200\nyou can see why it says that you can\n00:08:09,210 --> 00:08:11,060\npossibly see why it says re Newtown and\n00:08:11,070 --> 00:08:12,380\nbecause of the sort of jungle looking\n00:08:12,390 --> 00:08:14,750\nbackground or something orange in the\n00:08:14,760 --> 00:08:18,170\nmiddle but it fails to get the right\n00:08:18,180 --> 00:08:20,600\nanswer it can however deal with a wide\n00:08:20,610 --> 00:08:24,050\nrange of different objects if you look\n00:08:24,060 --> 00:08:26,830\non the left I would have said microwave\n00:08:26,840 --> 00:08:29,060\nas my first answer the labels are very\n00:08:29,070 --> 00:08:31,250\nsystematic so actually the correct\n00:08:31,260 --> 00:08:33,680\nanswer there's electric range and does\n00:08:33,690 --> 00:08:35,060\nget it in his top five in the middle\n00:08:35,070 --> 00:08:37,940\nit's getting a turnstile which is a\n00:08:37,950 --> 00:08:39,350\ndistributed object it does can't it can\n00:08:39,360 --> 00:08:41,000\ndo more than just recognize compact\n00:08:41,010 --> 00:08:42,709\nthings and it can also deal with\n00:08:42,719 --> 00:08:46,340\npictures as well as real scenes like the\n00:08:46,350 --> 00:08:49,130\nbulletproof vest and it makes them very\n00:08:49,140 --> 00:08:50,840\ncool errors if you look at the image on\n00:08:50,850 --> 00:08:53,569\nthe left that's\n00:08:53,579 --> 00:08:55,519\nearphone it doesn't get anything like an\n00:08:55,529 --> 00:08:58,069\nearphone but if you look at its fourth\n00:08:58,079 --> 00:08:59,300\nbet it thinks it's an ant until you\n00:08:59,310 --> 00:09:00,710\nreally think that's crazy\n00:09:00,720 --> 00:09:02,090\nbut then if you look at it carefully you\n00:09:02,100 --> 00:09:03,620\ncan see it's a view for an ant from\n00:09:03,630 --> 00:09:05,600\nunderneath the eyes are looking down on\n00:09:05,610 --> 00:09:07,699\nyou and you can see the antennae behind\n00:09:07,709 --> 00:09:09,939\nit it's not the kind of view of an ant\n00:09:09,949 --> 00:09:12,530\nyou'd like to have if you're a green fly\n00:09:12,540 --> 00:09:14,480\nif you look at the one on the right it\n00:09:14,490 --> 00:09:19,059\nhis answers are cylindrical objects\n00:09:21,600 --> 00:09:25,699\nanother task that neural Nets and I very\n00:09:25,709 --> 00:09:26,900\ngood at is speech recognition or at\n00:09:26,910 --> 00:09:29,930\nleast part of a speech recognition\n00:09:29,940 --> 00:09:33,139\nsystem so speech recognition systems\n00:09:33,149 --> 00:09:35,569\nhave several stages first they pre\n00:09:35,579 --> 00:09:38,420\nprocess the sound wave to get a vector\n00:09:38,430 --> 00:09:41,809\nof acoustic coefficients for each 10\n00:09:41,819 --> 00:09:42,980\nmilliseconds of sine wave and so they\n00:09:42,990 --> 00:09:46,249\nget a hundred of those vectors per\n00:09:46,259 --> 00:09:48,410\nsecond they then take a few adjacent\n00:09:48,420 --> 00:09:51,949\nvectors of acoustic coefficients and\n00:09:51,959 --> 00:09:54,829\nthey need to place bets on which part of\n00:09:54,839 --> 00:09:56,749\nwhich phoneme is being spoken so they\n00:09:56,759 --> 00:09:58,759\nlook at this little window and they say\n00:09:58,769 --> 00:10:00,740\nin the middle of this window what do I\n00:10:00,750 --> 00:10:04,490\nthink the phoneme is and which part of\n00:10:04,500 --> 00:10:06,829\nthe phoneme is it and a good speech\n00:10:06,839 --> 00:10:08,840\nrecognition system will have many\n00:10:08,850 --> 00:10:10,249\nalternative models for a phoneme and\n00:10:10,259 --> 00:10:13,639\neach model it might have three different\n00:10:13,649 --> 00:10:15,199\nparts so it might have many thousands of\n00:10:15,209 --> 00:10:17,720\nalternative fragments that it thinks\n00:10:17,730 --> 00:10:19,400\nthis might be and you have to place bets\n00:10:19,410 --> 00:10:22,970\non all those thousands of alternatives\n00:10:22,980 --> 00:10:25,699\nand then once you place those bets you\n00:10:25,709 --> 00:10:29,840\nhave a decoding stage that does the best\n00:10:29,850 --> 00:10:32,900\njob it can of using plausible bets but\n00:10:32,910 --> 00:10:35,960\npiecing them together into a sequence of\n00:10:35,970 --> 00:10:40,819\nbets that corresponds to the kinds of\n00:10:40,829 --> 00:10:43,069\nthings that people say currently deep\n00:10:43,079 --> 00:10:45,350\nneural networks pioneered by George Dahl\n00:10:45,360 --> 00:10:47,660\nand Abdul Rahman Muhammad of the\n00:10:47,670 --> 00:10:49,670\nUniversity of Toronto are doing better\n00:10:49,680 --> 00:10:51,470\nthan previous machine learning methods\n00:10:51,480 --> 00:10:52,699\nfor the acoustic model and they're now\n00:10:52,709 --> 00:11:01,340\nbeginning to be used in practical\n00:11:01,350 --> 00:11:04,160\nsystems so Darla Mohammed developed a\n00:11:04,170 --> 00:11:10,430\nsystem that uses many layers\n00:11:10,440 --> 00:11:13,490\nof binary neurons to take some acoustic\n00:11:13,500 --> 00:11:15,470\nframes and make bets about the labels\n00:11:15,480 --> 00:11:17,960\nthey were doing it on a fairly small\n00:11:17,970 --> 00:11:20,210\ndatabase and then used 183 alternative\n00:11:20,220 --> 00:11:21,740\nlengths and to get their system to work\n00:11:21,750 --> 00:11:23,389\nwell they did some pre training which\n00:11:23,399 --> 00:11:26,540\nwill be described in the second half of\n00:11:26,550 --> 00:11:27,319\nthe course after standard post\n00:11:27,329 --> 00:11:29,960\nprocessing\n00:11:29,970 --> 00:11:31,879\nthey got twenty point seven percent\n00:11:31,889 --> 00:11:33,769\nerror rate on a very standard benchmark\n00:11:33,779 --> 00:11:36,949\nwhich is kind of like the N missed for\n00:11:36,959 --> 00:11:38,840\nspeech the best previous result on that\n00:11:38,850 --> 00:11:40,759\nbenchmark for speech independent\n00:11:40,769 --> 00:11:43,819\nrecognition was twenty four point four\n00:11:43,829 --> 00:11:46,840\npercent and a very experienced receipt\n00:11:46,850 --> 00:11:48,829\nspeech researcher at Microsoft Research\n00:11:48,839 --> 00:11:51,199\nrealized that that was a big enough\n00:11:51,209 --> 00:11:52,579\nimprovement that probably this would\n00:11:52,589 --> 00:11:57,079\nchange the way speech recognition\n00:11:57,089 --> 00:12:00,220\nsystems were done and indeed it has so\n00:12:00,230 --> 00:12:03,069\nif you look at recent results from\n00:12:03,079 --> 00:12:05,780\nseveral different leading speech groups\n00:12:05,790 --> 00:12:08,329\nMicrosoft showed that this kind of deep\n00:12:08,339 --> 00:12:10,699\nneural network when used as the acoustic\n00:12:10,709 --> 00:12:12,170\nmodel in a speech system reduce the\n00:12:12,180 --> 00:12:13,579\nerror rate from thirty seven point four\n00:12:13,589 --> 00:12:16,460\npercent to eighteen point five percent\n00:12:16,470 --> 00:12:18,110\nor alternatively you could view it as\n00:12:18,120 --> 00:12:20,600\nreducing the amount of training data you\n00:12:20,610 --> 00:12:21,949\nneeded from two thousand hours down to\n00:12:21,959 --> 00:12:25,490\nthree hundred nine hours to get\n00:12:25,500 --> 00:12:29,019\ncomparable performance IBM which has the\n00:12:29,029 --> 00:12:32,269\nbest system for one of the standard\n00:12:32,279 --> 00:12:35,360\nspeech recognition tasks for large with\n00:12:35,370 --> 00:12:37,400\nlibrary speech recognition showed that\n00:12:37,410 --> 00:12:40,069\neven it's very highly tuned system that\n00:12:40,079 --> 00:12:42,949\nwas getting 18.8% can be beaten by one\n00:12:42,959 --> 00:12:45,050\nof these deep neural networks and Google\n00:12:45,060 --> 00:12:47,720\nfairly recently trained to deep neural\n00:12:47,730 --> 00:12:49,670\nnetwork on a large amount of speech five\n00:12:49,680 --> 00:12:51,439\nthousand eight hundred hours that was\n00:12:51,449 --> 00:12:54,590\nstill much less than their trend they\n00:12:54,600 --> 00:12:56,780\nguess in mixture model on but even with\n00:12:56,790 --> 00:12:59,329\nmuch less data it did a lot better than\n00:12:59,339 --> 00:13:01,370\nthe technology they had performed so\n00:13:01,380 --> 00:13:03,050\nreduce the error rate from 16 percent to\n00:13:03,060 --> 00:13:05,660\ntwelve point three percent and the error\n00:13:05,670 --> 00:13:08,870\nrate is still falling and in the latest\n00:13:08,880 --> 00:13:10,460\nAndroid if you do voice search it's\n00:13:10,470 --> 00:13:12,949\nusing one of these deep neural networks\n00:13:12,949 --> 00:13:12,959\n\n00:13:12,959 --> 00:13:15,380\nrecognition"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for t in glob.glob(\"/content/transcripts/Lecture*.srt\"):\n",
    "    print(t)\n",
    "    print(get_num_tokens(load_transcription(t)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMYFGa_mHzN-",
    "outputId": "37673575-e1b2-491d-bc8f-a258aa997fb8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/transcripts/Lecture 4.1 — Learning to predict the next word — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [_LzxJ1LbSl4].en.srt\n",
      "7193\n",
      "/content/transcripts/Lecture 7.5 — Long term Short term memory — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [OtFAECd_IXQ].en.srt\n",
      "5297\n",
      "/content/transcripts/Lecture 2.1 — Types of neural network architectures — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [6cHupvcxA38].en.srt\n",
      "4224\n",
      "/content/transcripts/Lecture 8.3 — Predicting the next character using HF — [ Deep Learning ｜  Hinton ｜ UofT ] [74Hj4By5kjg].en.srt\n",
      "6724\n",
      "/content/transcripts/Lecture 4.3 — The softmax output function — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [PHP8beSz5o4].en.srt\n",
      "4037\n",
      "/content/transcripts/Lecture 5.1 — Why object recognition is difficult — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [XSmoVWhM8G4].en.srt\n",
      "2713\n",
      "/content/transcripts/Lecture 7.1 — Modeling sequences  a brief overview — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [V0-2pV8vQ84].en.srt\n",
      "9658\n",
      "/content/transcripts/Lecture 3.4 — The backpropagation algorithm — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [VCT1N0EsGj0].en.srt\n",
      "6507\n",
      "/content/transcripts/Lecture 11.3 — Hopfield nets with hidden units— [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [GZTmqMSxAR4].en.srt\n",
      "5507\n",
      "/content/transcripts/Lecture 8.2 — Modeling character strings — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [GhGBrxStXuA].en.srt\n",
      "7631\n",
      "/content/transcripts/Lecture 10.5 — Dropout — [ Deep Learning ｜ Geoffrey Hinton ｜ Toronto ] [iCbVPfk_5CQ].en.srt\n",
      "5014\n",
      "/content/transcripts/Lecture 3.3 — Learning weights of logistic output neuron — [ Deep Learning ｜ Hinton ｜ UofT ] [MVT-bHFqZ9o].en.srt\n",
      "2013\n",
      "/content/transcripts/Lecture 2.3 — A geometrical view of perceptrons — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [TNhgCkYDc8M].en.srt\n",
      "3563\n",
      "/content/transcripts/Lecture 15.1 — From PCA to autoencoders — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [PSOt7u8u23w].en.srt\n",
      "4453\n",
      "/content/transcripts/Lecture 5.2 — Achieving viewpoint invariance — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [ARzsyifxGEI].en.srt\n",
      "3515\n",
      "/content/transcripts/Lecture 2.4 — Why the learning works — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [92hto4KwlGI].en.srt\n",
      "2768\n",
      "/content/transcripts/Lecture 3.2 — The error surface for a linear neuron — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [tafPPLVuB2s].en.srt\n",
      "2771\n",
      "/content/transcripts/Lecture 12.4 — An example of RBM learning — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [iHaS6O1eox4].en.srt\n",
      "4371\n",
      "/content/transcripts/Lecture 4.5 — Dealing with many possible outputs — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [qgjzwJwKiBc].en.srt\n",
      "7008\n",
      "/content/transcripts/Lecture 16.1 — Learning a joint model of images and captions — [ Deep Learning ｜ Hinton ｜ UofT ] [kVuF-9BaDLs].en.srt\n",
      "4698\n",
      "/content/transcripts/Lecture 9.5 — The Bayesian interpretation of weight decay — [ Deep Learning ｜ Hinton ｜ UofT ] [PD2DmW9E_Q0].en.srt\n",
      "5630\n",
      "/content/transcripts/Lecture 13.4 — The wake sleep algorithm — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [FBkhbqrFyo4].en.srt\n",
      "7457\n",
      "/content/transcripts/Lecture 14.2 — Discriminative learning for DBNs — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [QCBkbDpsheQ].en.srt\n",
      "5750\n",
      "/content/transcripts/Lecture 4.2 — A brief diversion into cognitive science — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [QJw5CN_0zxU].en.srt\n",
      "2468\n",
      "/content/transcripts/Lecture 14.4 — Modeling real valued data with an RBM — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [SnbfQwJLNk8].en.srt\n",
      "5424\n",
      "/content/transcripts/Lecture 5.3 — Convolutional nets for digit recognition — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [w7qvEv1EKZ0].en.srt\n",
      "9247\n",
      "/content/transcripts/Lecture 11.5 — How a Boltzmann machine models data — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [kytxEr0KK7Q].en.srt\n",
      "6894\n",
      "/content/transcripts/Lecture 14.1 — Learning layers of features by stacking RBMs — [ Deep Learning ｜ Hinton ｜ UofT ] [Y3beRvYSA90].en.srt\n",
      "10261\n",
      "/content/transcripts/Lecture 2.2 — Perceptrons  first generation neural networks — [ Deep Learning ｜ Hinton ｜ UofT ] [5tHN6Y70d5Y].en.srt\n",
      "4689\n",
      "/content/transcripts/Lecture 16.4 — The fog of progress — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [FOqMeBM3EIE].en.srt\n",
      "1520\n",
      "/content/transcripts/Lecture 11.1 — Hopfield Nets — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [Rs1XMS8NqB4].en.srt\n",
      "6939\n",
      "/content/transcripts/Lecture 15.5 — Learning binary codes for image retrieval — [ Deep Learning ｜ Hinton ｜ UofT ] [j1ry6Pg7X14].en.srt\n",
      "5714\n",
      "/content/transcripts/Lecture 9.4 — Introduction to the full Bayesian approach — [ Deep Learning ｜ Hinton ｜ UofT ] [jN5uYO9qllc].en.srt\n",
      "5797\n",
      "/content/transcripts/Lecture 10.3 — The idea of full Bayesian learning — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [1A6Md5ZYyW0].en.srt\n",
      "4467\n",
      "/content/transcripts/Lecture 12.1 — Boltzmann machine learning — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [2k9XTr_jNfE].en.srt\n",
      "6845\n",
      "/content/transcripts/Lecture 7.4 — Why it is difficult to train an RNN — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [WCngMib2mb4].en.srt\n",
      "4267\n",
      "/content/transcripts/Lecture 8.1 — A brief overview of Hessian free optimization — [ Deep Learning ｜ Hinton ｜ UofT ] [XxQ4hgcKDlY].en.srt\n",
      "8446\n",
      "/content/transcripts/Lecture 1.5 — Three types of learning — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [nrkpEx7tA2Y].en.srt\n",
      "4459\n",
      "/content/transcripts/Lecture 15.4 — Semantic Hashing — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [3BDc0H9C9dw].en.srt\n",
      "5020\n",
      "/content/transcripts/Lecture 6.3 — The momentum method Neural — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [z2rTn8Evav8].en.srt\n",
      "4776\n",
      "/content/transcripts/Lecture 7.3 — A toy example of training an RNN — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [sGXOyI5I_Fw].en.srt\n",
      "3207\n",
      "/content/transcripts/Lecture 6 5 — Rmsprop  normalize the gradient — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [XhZahXzEuNo].en.srt\n",
      "6799\n",
      "/content/transcripts/Lecture 1.1 — Why do we need machine learning — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [OVwEeSsSCHE].en.srt\n",
      "7991\n",
      "/content/transcripts/Lecture 11.4 — Using stochastic units to improve search — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [4vBqFO9bPeg].en.srt\n",
      "6056\n",
      "/content/transcripts/Lecture 3.1 — Learning the weights of a linear neuron — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [6gZjRI_gnGc].en.srt\n",
      "6635\n",
      "/content/transcripts/Lecture 6.2 — A bag of tricks for mini batch gradient descent — [ Deep Learning ｜ Hinton ｜ UofT ] [iNucJB-0vYs].en.srt\n",
      "7951\n",
      "/content/transcripts/Lecture 10.1 — Why it helps to combine models — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [kZ7JJOMt5Kw].en.srt\n",
      "7555\n",
      "/content/transcripts/Lecture 5.4 — Convolutional nets for object recognition — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [924oc7aLH-g].en.srt\n",
      "11096\n",
      "/content/transcripts/Lecture 12.2 — More efficient ways to get the statistics — [ Deep Learning ｜ Hinton ｜ UofT ] [CkZ9HA6KUnA].en.srt\n",
      "7821\n",
      "/content/transcripts/Lecture 11.2 — Dealing with spurious minima — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [HJfhdksIqUE].en.srt\n",
      "6697\n",
      "/content/transcripts/Lecture 10.4 — Making full Bayesian learning practical — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [RsC9xfHYYH0].en.srt\n",
      "3616\n",
      "/content/transcripts/Lecture 13.3 — Learning sigmoid belief nets — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [HacQtntlLcw].en.srt\n",
      "6371\n",
      "/content/transcripts/Lecture 16.3 — Bayesian optimization of hyper parameters — [ Deep Learning ｜ Hinton ｜ UofT ] [i0cKa0di_lo].en.srt\n",
      "8207\n",
      "/content/transcripts/Lecture 8.4 — Echo State Networks — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [prXjoD9rEHo].en.srt\n",
      "5194\n",
      "/content/transcripts/Lecture 12.3 — Restricted Boltzmann Machines — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [EZOpZzUKl48].en.srt\n",
      "5888\n",
      "/content/transcripts/Lecture 6.4 — Adaptive learning rates for each connection — [ Deep Learning ｜ Hinton ｜ UofT ] [Gkdq3dHYQtk].en.srt\n",
      "3327\n",
      "/content/transcripts/Lecture 7.2 — Training RNNs with back propagation — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [4gOdNtVNZtk].en.srt\n",
      "3676\n",
      "/content/transcripts/Lecture 1.4 — A simple example of learning — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [mnTJezQOIDU].en.srt\n",
      "3142\n",
      "/content/transcripts/Lecture 15.2 — Deep autoencoders — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [6jhhIPdgkp0].en.srt\n",
      "2364\n",
      "/content/transcripts/Lecture 13.2 — Belief Nets — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [1CgojqlHrcE].en.srt\n",
      "8272\n",
      "/content/transcripts/Lecture 9.1 — Overview of ways to improve generalization — [ Deep Learning ｜  Hinton ｜ UofT ] [MbpaeKYMXVk].en.srt\n",
      "6763\n",
      "/content/transcripts/Lecture 6.1 — Overview of mini batch gradient descent — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [EANflep-cog].en.srt\n",
      "5161\n",
      "/content/transcripts/Lecture 12.5 — RBMs for collaborative filtering — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [on5lto0rG48].en.srt\n",
      "4697\n",
      "/content/transcripts/Lecture 2.5 — What perceptrons cant do — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [16qJwiH-FdE].en.srt\n",
      "7838\n",
      "/content/transcripts/Lecture 13.1 — The ups and downs of backpropagation — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [lDFY8vQe6-g].en.srt\n",
      "5961\n",
      "/content/transcripts/Lecture 9.3 — Using noise as a regularizer — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [pu2d_AFuwdQ].en.srt\n",
      "3913\n",
      "/content/transcripts/Lecture 9.2 — Limiting the size of the weights — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [Ukb5yqeF1po].en.srt\n",
      "3602\n",
      "/content/transcripts/Lecture 1.2 — What are neural networks — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [jNBYZbDWyQk].en.srt\n",
      "4969\n",
      "/content/transcripts/Lecture 15.3 — Deep autoencoders for document retrieval — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [ZCNbjpcX0yg].en.srt\n",
      "4691\n",
      "/content/transcripts/Lecture 10.2 — Mixtures of Experts — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [FxrTtRvYQWk].en.srt\n",
      "7431\n",
      "/content/transcripts/Lecture 9.6 — MacKay  s quick and dirty method — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [CzrAOBC8ts0].en.srt\n",
      "1909\n",
      "/content/transcripts/Lecture 15.6 — Shallow autoencoders for pre training — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [xjlvVfEbhz4].en.srt\n",
      "4538\n",
      "/content/transcripts/Lecture 4.4 — Neuro probabilistic language models — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [wqUgMFMnlzI].en.srt\n",
      "4647\n",
      "/content/transcripts/Lecture 14.3 — Discriminative fine tuning — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [YPQjud6JaSE].en.srt\n",
      "4709\n",
      "/content/transcripts/Lecture 1.3 — Some simple models of neurons — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [VA9niXgGOsQ].en.srt\n",
      "4597\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "chapters_files = natsorted([file_path for file_path in glob.glob(\"/content/chapters/chapters*.txt\")])\n",
    "transcription_files = natsorted([file_path for file_path in glob.glob(\"/content/transcripts/Lecture*.srt\")])"
   ],
   "metadata": {
    "id": "YG3X4S6sHzK2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "chapters_files[:5]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7Yv_LY1HzH_",
    "outputId": "87b65e3c-7b98-4261-99e0-a70ab802fd76"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/content/chapters/chapters_1A6Md5ZYyW0.txt',\n",
       " '/content/chapters/chapters_1CgojqlHrcE.txt',\n",
       " '/content/chapters/chapters_2k9XTr_jNfE.txt',\n",
       " '/content/chapters/chapters_3BDc0H9C9dw.txt',\n",
       " '/content/chapters/chapters_4gOdNtVNZtk.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "transcription_files[:5]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C9-dTZNdHzE3",
    "outputId": "71bd3eea-f44c-452d-a6ff-7e01cf52fb2e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/content/transcripts/Lecture 1.1 — Why do we need machine learning — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [OVwEeSsSCHE].en.srt',\n",
       " '/content/transcripts/Lecture 1.2 — What are neural networks — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [jNBYZbDWyQk].en.srt',\n",
       " '/content/transcripts/Lecture 1.3 — Some simple models of neurons — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [VA9niXgGOsQ].en.srt',\n",
       " '/content/transcripts/Lecture 1.4 — A simple example of learning — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [mnTJezQOIDU].en.srt',\n",
       " '/content/transcripts/Lecture 1.5 — Three types of learning — [ Deep Learning ｜ Geoffrey Hinton ｜ UofT ] [nrkpEx7tA2Y].en.srt']"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "video_ids = list(video_list_dict.keys())\n",
    "urls = list(video_list_dict.values())"
   ],
   "metadata": {
    "id": "Y90KPodqUCnb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(video_ids)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXMldi0zZZ1-",
    "outputId": "204e864d-13d9-4d77-fe17-f3ca64d3605b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data = []\n",
    "# Function to find the matching file based on the video ID\n",
    "def find_matching_file(file_list, key):\n",
    "    for file in file_list:\n",
    "        if key in file:\n",
    "            return file\n",
    "    return None\n",
    "# Loop through the video_list_dict\n",
    "for video_id, url in video_list_dict.items():\n",
    "    # Initialize an empty dictionary to store data for each set\n",
    "    entry = {}\n",
    "\n",
    "    entry[\"video_id\"] = video_id\n",
    "    entry[\"url\"] = url\n",
    "\n",
    "    # Find the corresponding chapter and transcription files based on the video ID\n",
    "    chapter_file = find_matching_file(chapters_files, video_id)\n",
    "    transcription_file = find_matching_file(transcription_files, video_id)\n",
    "\n",
    "    # Check if matching files were found\n",
    "    if chapter_file is not None and transcription_file is not None:\n",
    "        # Read the chapter file and store its contents\n",
    "        with open(chapter_file, \"r\") as f:\n",
    "            entry[\"chapters_section\"] = f.read()\n",
    "\n",
    "        # Read the transcription file and store its contents\n",
    "        with open(transcription_file, \"r\") as f:\n",
    "            entry[\"transcription\"] = f.read()\n",
    "\n",
    "        # Append the dictionary to the list\n",
    "        data.append(entry)\n",
    "\n"
   ],
   "metadata": {
    "id": "IEMBytOpHzBu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to generate the new JSON structure\n",
    "def generate_new_json_structure(original_data):\n",
    "    new_data_list = []\n",
    "\n",
    "    for entry in original_data:\n",
    "        new_data = {\"messages\": []}\n",
    "\n",
    "        # Add a system message\n",
    "        system_message = {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "        new_data[\"messages\"].append(system_message)\n",
    "\n",
    "        url = entry[\"url\"]\n",
    "        chapters = entry[\"chapters_section\"]\n",
    "        transcription = entry[\"transcription\"]\n",
    "\n",
    "        # Add user message\n",
    "        user_message_content = f\"Given this Youtube video transcript: {transcription} I want you to create a chapters section for this Youtube video with the following format:\\n\"\n",
    "        user_message_content += \"Chapters:\\n\"\n",
    "        user_message_content += \"<double digit:time stamp> - <Concise phrase of a major part of the video>\"\n",
    "        user_message = {\"role\": \"user\", \"content\": user_message_content}\n",
    "        new_data[\"messages\"].append(user_message)\n",
    "\n",
    "        # Add assistant message\n",
    "        assistant_message_content = chapters  # Assuming chapters are already formatted as desired\n",
    "        assistant_message = {\"role\": \"assistant\", \"content\": assistant_message_content}\n",
    "        new_data[\"messages\"].append(assistant_message)\n",
    "\n",
    "        new_data_list.append(new_data)\n",
    "\n",
    "    return new_data_list\n",
    "\n",
    "\n",
    "# Generate the new JSON structure\n",
    "new_data_list = generate_new_json_structure(data)\n",
    "# Write the new JSON structure to a .jsonl file\n",
    "with open(\"./dataset_fine_tunning.jsonl\", \"w\") as f:\n",
    "    for item in new_data_list:\n",
    "        json.dump(item, f)\n",
    "        f.write('\\n')"
   ],
   "metadata": {
    "id": "CmjaCdiQHy4t"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_path = \"./dataset_fine_tunning.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bAw_jVLb6rz",
    "outputId": "074cea6a-f1b2-436c-c214-f14e73e38c41"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num examples: 75\n",
      "First example:\n",
      "{'role': 'system', 'content': 'You are a helpful assistant.'}\n",
      "{'role': 'user', 'content': \"Given this Youtube video transcript: 00:00:03,780 --> 00:00:06,070\\nhello welcome to the Coursera course on\\n00:00:06,080 --> 00:00:09,020\\nneural networks for machine learning\\n00:00:09,030 --> 00:00:11,270\\nbefore we get into the details of neural\\n00:00:11,280 --> 00:00:13,120\\nnetwork learning algorithms I want to\\n00:00:13,130 --> 00:00:16,400\\ntalk a little bit about machine learning\\n00:00:16,410 --> 00:00:18,590\\nwhy we need machine learning the kinds\\n00:00:18,600 --> 00:00:22,279\\nof things we use it for and show you\\n00:00:22,289 --> 00:00:25,220\\nsome examples of what it can do so the\\n00:00:25,230 --> 00:00:27,410\\nreason we need machine learning is that\\n00:00:27,420 --> 00:00:30,109\\nthe some problems where it's very hard\\n00:00:30,119 --> 00:00:31,479\\nto write the programs recognizing a\\n00:00:31,489 --> 00:00:34,400\\nthree-dimensional object for example\\n00:00:34,410 --> 00:00:35,900\\nwhen it's from a novel viewpoint in new\\n00:00:35,910 --> 00:00:39,860\\nlighting conditions in a cluttered scene\\n00:00:39,870 --> 00:00:41,420\\nis very hard to do we don't know what\\n00:00:41,430 --> 00:00:44,540\\nprograms right because we don't know how\\n00:00:44,550 --> 00:00:46,279\\nit's done in our brain and even if we\\n00:00:46,289 --> 00:00:47,630\\ndid know what programs right it might be\\n00:00:47,640 --> 00:00:49,990\\nthat it was a horrendously complicated\\n00:00:50,000 --> 00:00:52,970\\nprogram\\n00:00:52,980 --> 00:00:55,580\\nanother example is detecting a\\n00:00:55,590 --> 00:00:58,099\\nfraudulent credit card transaction where\\n00:00:58,109 --> 00:01:00,260\\nthere may not be any nice simple rules\\n00:01:00,270 --> 00:01:02,090\\nthat will tell you it's fraudulent you\\n00:01:02,100 --> 00:01:05,719\\nreally need to combine a very large\\n00:01:05,729 --> 00:01:08,060\\nnumber of not very reliable rules and\\n00:01:08,070 --> 00:01:09,710\\nalso those rules change over time\\n00:01:09,720 --> 00:01:12,980\\nbecause people change the tricks they\\n00:01:12,990 --> 00:01:14,870\\nuse for fraud so we need a complicated\\n00:01:14,880 --> 00:01:19,399\\nprogram that combines unreliable rules\\n00:01:19,409 --> 00:01:21,890\\nand that we can change easily the\\n00:01:21,900 --> 00:01:24,140\\nmachine learning approach is to say\\n00:01:24,150 --> 00:01:26,780\\ninstead of writing each program by hand\\n00:01:26,790 --> 00:01:28,429\\nfor each specific task for a particular\\n00:01:28,439 --> 00:01:30,800\\ntask we'll collect a lot of examples\\n00:01:30,810 --> 00:01:34,010\\nthat specify the correct output for a\\n00:01:34,020 --> 00:01:36,859\\ngiven input a machine learning algorithm\\n00:01:36,869 --> 00:01:40,370\\nthen takes these examples and produces a\\n00:01:40,380 --> 00:01:42,590\\nprogram that does the job the program\\n00:01:42,600 --> 00:01:43,999\\nproduced by the learning algorithm may\\n00:01:44,009 --> 00:01:46,969\\nlook very different from a typical\\n00:01:46,979 --> 00:01:48,530\\nhandwritten program for example it might\\n00:01:48,540 --> 00:01:52,399\\ncontain millions of numbers about how\\n00:01:52,409 --> 00:01:54,319\\nyou weight different kinds of errands if\\n00:01:54,329 --> 00:01:55,940\\nwe do it right the program should work\\n00:01:55,950 --> 00:02:00,080\\nfor new cases as well as ones it's\\n00:02:00,090 --> 00:02:01,580\\ntraining on and if the data changes we\\n00:02:01,590 --> 00:02:04,280\\nshould be able to change the program\\n00:02:04,290 --> 00:02:09,109\\nrelatively easily by retraining it on\\n00:02:09,119 --> 00:02:11,059\\nthe new data and now massive amounts of\\n00:02:11,069 --> 00:02:12,350\\ncomputation are cheaper than paying\\n00:02:12,360 --> 00:02:13,650\\nsomeone to write a program for a\\n00:02:13,660 --> 00:02:16,530\\nspecific task\\n00:02:16,540 --> 00:02:19,050\\nso we can afford big complicated machine\\n00:02:19,060 --> 00:02:23,970\\nlearning programs to produce the start\\n00:02:23,980 --> 00:02:25,440\\ntask specific systems for some examples\\n00:02:25,450 --> 00:02:27,950\\nof the things that are best done by\\n00:02:27,960 --> 00:02:31,290\\nusing a learning algorithm are\\n00:02:31,300 --> 00:02:34,650\\nrecognizing patterns so for example\\n00:02:34,660 --> 00:02:37,580\\nobjects in real scenes or the identities\\n00:02:37,590 --> 00:02:42,210\\nor expressions of people's faces or\\n00:02:42,220 --> 00:02:45,540\\nspoken words there's also recognizing\\n00:02:45,550 --> 00:02:47,070\\nanomalies so an unusual sequence of\\n00:02:47,080 --> 00:02:50,640\\ncredit-card transactions will be an\\n00:02:50,650 --> 00:02:53,130\\nanomaly another example of an anomaly\\n00:02:53,140 --> 00:02:55,800\\nwould be an unusual pattern of sensor\\n00:02:55,810 --> 00:02:57,930\\nreadings in a nuclear power plant and\\n00:02:57,940 --> 00:02:59,370\\nyou wouldn't really want to have to deal\\n00:02:59,380 --> 00:03:00,990\\nwith those by doing supervised learning\\n00:03:01,000 --> 00:03:03,960\\nwhere you look at the ones that blow up\\n00:03:03,970 --> 00:03:05,610\\nand see what what caused them to blow up\\n00:03:05,620 --> 00:03:07,560\\nyou'd really like to recognize that\\n00:03:07,570 --> 00:03:09,750\\nsomething funny is happening without\\n00:03:09,760 --> 00:03:13,260\\nhaving any supervision signal it's just\\n00:03:13,270 --> 00:03:16,470\\nnot behaving in its normal way and then\\n00:03:16,480 --> 00:03:18,630\\nthis prediction so typically predicting\\n00:03:18,640 --> 00:03:21,210\\nfuture stock prices or currency exchange\\n00:03:21,220 --> 00:03:22,980\\nrates or predicting which movies a\\n00:03:22,990 --> 00:03:24,990\\nperson will like from knowing which\\n00:03:25,000 --> 00:03:29,640\\nother movies they like and which movies\\n00:03:29,650 --> 00:03:33,000\\na lot of other people liked so in this\\n00:03:33,010 --> 00:03:34,530\\ncourse I knees a standard example for\\n00:03:34,540 --> 00:03:38,310\\nexplaining a lot of the machine learning\\n00:03:38,320 --> 00:03:40,980\\nalgorithms this is done in a lot of\\n00:03:40,990 --> 00:03:44,820\\nscience in genetics for example a lot of\\n00:03:44,830 --> 00:03:46,500\\ngenetics is done on fruit flies and the\\n00:03:46,510 --> 00:03:49,199\\nreason is they're convenient they breed\\n00:03:49,209 --> 00:03:53,430\\nfast and a lot is already known about\\n00:03:53,440 --> 00:03:56,580\\nthe genesis of fruit flies the emne\\n00:03:56,590 --> 00:03:58,050\\nstata basis of handwritten digits is the\\n00:03:58,060 --> 00:04:03,240\\nmachine learning equivalent of fruit\\n00:04:03,250 --> 00:04:06,510\\nflies it's publicly available we can get\\n00:04:06,520 --> 00:04:08,190\\nmachine learning out rooms to learn how\\n00:04:08,200 --> 00:04:10,410\\nto recognize these hundred and digits\\n00:04:10,420 --> 00:04:13,740\\nquite quickly so it's easy to try lots\\n00:04:13,750 --> 00:04:15,630\\nof variations and we know huge amounts\\n00:04:15,640 --> 00:04:18,180\\nabout how well different machine\\n00:04:18,190 --> 00:04:19,380\\nlearning methods do on any list and in\\n00:04:19,390 --> 00:04:20,820\\nparticular the different machine\\n00:04:20,830 --> 00:04:23,010\\nlearning methods were implemented by\\n00:04:23,020 --> 00:04:26,340\\npeople who believed in them so we can\\n00:04:26,350 --> 00:04:27,330\\nrely on those results so for all those\\n00:04:27,340 --> 00:04:31,680\\nreasons we're going to use\\n00:04:31,690 --> 00:04:34,830\\nas our standard task here's an example\\n00:04:34,840 --> 00:04:36,600\\nof some of the digits in n rest these\\n00:04:36,610 --> 00:04:40,370\\nare ones that were correctly recognized\\n00:04:40,380 --> 00:04:42,390\\nby neural net the first time it saw them\\n00:04:42,400 --> 00:04:45,270\\nbut they're ones where the neural net\\n00:04:45,280 --> 00:04:49,250\\nwasn't very confident and you can see\\n00:04:49,260 --> 00:04:51,990\\nwhy I've arranged these digits in\\n00:04:52,000 --> 00:04:54,840\\nstandard scanline order so zeros than\\n00:04:54,850 --> 00:04:55,830\\nones and twos and so on if you look at a\\n00:04:55,840 --> 00:04:58,650\\nbunch of two's\\n00:04:58,660 --> 00:05:01,860\\nlike the ones in the green rectangle you\\n00:05:01,870 --> 00:05:04,290\\ncan see that if you knew they were a\\n00:05:04,300 --> 00:05:07,110\\nhandwritten digit you'd probably guess\\n00:05:07,120 --> 00:05:09,270\\nthey were twos but it's very hard to say\\n00:05:09,280 --> 00:05:10,740\\nwhat it is that makes them twos there's\\n00:05:10,750 --> 00:05:13,050\\nnothing simple that they all have in\\n00:05:13,060 --> 00:05:15,450\\ncommon in particular if you try and\\n00:05:15,460 --> 00:05:18,060\\noverlay one on another you'll see it\\n00:05:18,070 --> 00:05:20,670\\ndoesn't fit and even if you skew it a\\n00:05:20,680 --> 00:05:22,350\\nbit it's very hard to make them overlay\\n00:05:22,360 --> 00:05:25,500\\non each other so template isn't going to\\n00:05:25,510 --> 00:05:27,150\\ndo the job and in particular template is\\n00:05:27,160 --> 00:05:29,040\\ngoing to be very hard to find that'll\\n00:05:29,050 --> 00:05:31,110\\nfit those twos in the green box and\\n00:05:31,120 --> 00:05:34,950\\nwon't also fit the things in the red\\n00:05:34,960 --> 00:05:36,900\\nboxes so that's one thing that makes\\n00:05:36,910 --> 00:05:40,469\\nrecognizing handwritten digits a good\\n00:05:40,479 --> 00:05:41,610\\ntask for machine learning now I don't\\n00:05:41,620 --> 00:05:44,640\\nwant you to think that's the only thing\\n00:05:44,650 --> 00:05:46,290\\nwe can do it's a relatively simple thing\\n00:05:46,300 --> 00:05:49,560\\nfor a machine learning system to do now\\n00:05:49,570 --> 00:05:51,089\\nand to motivate the rest of the course I\\n00:05:51,099 --> 00:05:54,960\\nwant to show you some examples are much\\n00:05:54,970 --> 00:05:58,170\\nmore difficult things so we now have\\n00:05:58,180 --> 00:06:01,400\\nneural nets with approaching 100 million\\n00:06:01,410 --> 00:06:05,550\\nparameters in them that can recognize a\\n00:06:05,560 --> 00:06:07,440\\nthousand different object classes in 1.3\\n00:06:07,450 --> 00:06:11,339\\nmillion high resolution training images\\n00:06:11,349 --> 00:06:13,529\\ngot from the web so there was a\\n00:06:13,539 --> 00:06:16,200\\ncompetition in 2010 and the best system\\n00:06:16,210 --> 00:06:18,510\\ngot 47 percent error rate if you look at\\n00:06:18,520 --> 00:06:20,400\\nhis first choice and 25 percent error\\n00:06:20,410 --> 00:06:22,680\\nrate if you say got it right if it was\\n00:06:22,690 --> 00:06:26,730\\nin its top 5 choices which isn't bad for\\n00:06:26,740 --> 00:06:28,800\\na thousand different objects Jitendra\\n00:06:28,810 --> 00:06:31,020\\nmalik who's an eminent neural net\\n00:06:31,030 --> 00:06:34,409\\nskeptic and a leading computer vision\\n00:06:34,419 --> 00:06:36,029\\nresearcher has said that this\\n00:06:36,039 --> 00:06:37,589\\ncompetition is a good test of whether\\n00:06:37,599 --> 00:06:39,620\\ndeep neural networks can work well for\\n00:06:39,630 --> 00:06:43,310\\nobject recognition\\n00:06:43,320 --> 00:06:45,590\\nand a very deep neural network can now\\n00:06:45,600 --> 00:06:47,660\\ndo considerably better than the thing\\n00:06:47,670 --> 00:06:49,940\\nthat won the competition it can get less\\n00:06:49,950 --> 00:06:51,500\\nthan 40 percent error for its first\\n00:06:51,510 --> 00:06:53,960\\nchoice and less than 20 percent our\\n00:06:53,970 --> 00:06:55,910\\nefforts top 5 choices I'll describe that\\n00:06:55,920 --> 00:06:58,700\\nin much more detail in lecture 5 here's\\n00:06:58,710 --> 00:07:00,710\\nsome examples of the kinds of images you\\n00:07:00,720 --> 00:07:02,270\\nhave to recognize these are images from\\n00:07:02,280 --> 00:07:06,650\\nthe test set that is never seen before\\n00:07:06,660 --> 00:07:08,750\\nand below the examples I'm showing you\\n00:07:08,760 --> 00:07:11,090\\nwhat the neural net thought the right\\n00:07:11,100 --> 00:07:12,830\\nanswer was where the length of the\\n00:07:12,840 --> 00:07:16,640\\nhorizontal bar is how confident it was\\n00:07:16,650 --> 00:07:18,380\\nand the correct answer is in red so if\\n00:07:18,390 --> 00:07:21,290\\nyou look in the middle a correctly\\n00:07:21,300 --> 00:07:23,030\\nidentified that as a snow plow but you\\n00:07:23,040 --> 00:07:24,980\\ncan see that his other choices were also\\n00:07:24,990 --> 00:07:27,350\\nfairly sensible it does look a little\\n00:07:27,360 --> 00:07:29,030\\nbit like a drilling platform and if you\\n00:07:29,040 --> 00:07:30,890\\nlook at its third choice a lifeboat\\n00:07:30,900 --> 00:07:32,360\\nit actually looks very like a lifeboat\\n00:07:32,370 --> 00:07:33,800\\nyou can see the flag on the front of the\\n00:07:33,810 --> 00:07:35,720\\nboat and the bridge of the boat and the\\n00:07:35,730 --> 00:07:38,810\\nflag at the back and the high surf in\\n00:07:38,820 --> 00:07:40,190\\nthe background so it's its errors tell\\n00:07:40,200 --> 00:07:42,380\\nyou a lot about how it's doing it and\\n00:07:42,390 --> 00:07:44,800\\nthey're very plausible errors if you\\n00:07:44,810 --> 00:07:47,000\\nlook on the left it gets it wrong\\n00:07:47,010 --> 00:07:49,640\\npossibly because the beak of the bird is\\n00:07:49,650 --> 00:07:52,630\\nmissing and cuz the feathers of the bird\\n00:07:52,640 --> 00:07:55,700\\nlook very like the wet fur of an otter\\n00:07:55,710 --> 00:07:57,140\\nbut he gets it in his top five and it\\n00:07:57,150 --> 00:07:58,940\\ndoes better than me I wouldn't know if\\n00:07:58,950 --> 00:08:01,730\\nthat was a quail or a roughed grouse or\\n00:08:01,740 --> 00:08:05,180\\na partridge if you look on the right he\\n00:08:05,190 --> 00:08:07,370\\ngets it completely wrong it a guillotine\\n00:08:07,380 --> 00:08:09,200\\nyou can see why it says that you can\\n00:08:09,210 --> 00:08:11,060\\npossibly see why it says re Newtown and\\n00:08:11,070 --> 00:08:12,380\\nbecause of the sort of jungle looking\\n00:08:12,390 --> 00:08:14,750\\nbackground or something orange in the\\n00:08:14,760 --> 00:08:18,170\\nmiddle but it fails to get the right\\n00:08:18,180 --> 00:08:20,600\\nanswer it can however deal with a wide\\n00:08:20,610 --> 00:08:24,050\\nrange of different objects if you look\\n00:08:24,060 --> 00:08:26,830\\non the left I would have said microwave\\n00:08:26,840 --> 00:08:29,060\\nas my first answer the labels are very\\n00:08:29,070 --> 00:08:31,250\\nsystematic so actually the correct\\n00:08:31,260 --> 00:08:33,680\\nanswer there's electric range and does\\n00:08:33,690 --> 00:08:35,060\\nget it in his top five in the middle\\n00:08:35,070 --> 00:08:37,940\\nit's getting a turnstile which is a\\n00:08:37,950 --> 00:08:39,350\\ndistributed object it does can't it can\\n00:08:39,360 --> 00:08:41,000\\ndo more than just recognize compact\\n00:08:41,010 --> 00:08:42,709\\nthings and it can also deal with\\n00:08:42,719 --> 00:08:46,340\\npictures as well as real scenes like the\\n00:08:46,350 --> 00:08:49,130\\nbulletproof vest and it makes them very\\n00:08:49,140 --> 00:08:50,840\\ncool errors if you look at the image on\\n00:08:50,850 --> 00:08:53,569\\nthe left that's\\n00:08:53,579 --> 00:08:55,519\\nearphone it doesn't get anything like an\\n00:08:55,529 --> 00:08:58,069\\nearphone but if you look at its fourth\\n00:08:58,079 --> 00:08:59,300\\nbet it thinks it's an ant until you\\n00:08:59,310 --> 00:09:00,710\\nreally think that's crazy\\n00:09:00,720 --> 00:09:02,090\\nbut then if you look at it carefully you\\n00:09:02,100 --> 00:09:03,620\\ncan see it's a view for an ant from\\n00:09:03,630 --> 00:09:05,600\\nunderneath the eyes are looking down on\\n00:09:05,610 --> 00:09:07,699\\nyou and you can see the antennae behind\\n00:09:07,709 --> 00:09:09,939\\nit it's not the kind of view of an ant\\n00:09:09,949 --> 00:09:12,530\\nyou'd like to have if you're a green fly\\n00:09:12,540 --> 00:09:14,480\\nif you look at the one on the right it\\n00:09:14,490 --> 00:09:19,059\\nhis answers are cylindrical objects\\n00:09:21,600 --> 00:09:25,699\\nanother task that neural Nets and I very\\n00:09:25,709 --> 00:09:26,900\\ngood at is speech recognition or at\\n00:09:26,910 --> 00:09:29,930\\nleast part of a speech recognition\\n00:09:29,940 --> 00:09:33,139\\nsystem so speech recognition systems\\n00:09:33,149 --> 00:09:35,569\\nhave several stages first they pre\\n00:09:35,579 --> 00:09:38,420\\nprocess the sound wave to get a vector\\n00:09:38,430 --> 00:09:41,809\\nof acoustic coefficients for each 10\\n00:09:41,819 --> 00:09:42,980\\nmilliseconds of sine wave and so they\\n00:09:42,990 --> 00:09:46,249\\nget a hundred of those vectors per\\n00:09:46,259 --> 00:09:48,410\\nsecond they then take a few adjacent\\n00:09:48,420 --> 00:09:51,949\\nvectors of acoustic coefficients and\\n00:09:51,959 --> 00:09:54,829\\nthey need to place bets on which part of\\n00:09:54,839 --> 00:09:56,749\\nwhich phoneme is being spoken so they\\n00:09:56,759 --> 00:09:58,759\\nlook at this little window and they say\\n00:09:58,769 --> 00:10:00,740\\nin the middle of this window what do I\\n00:10:00,750 --> 00:10:04,490\\nthink the phoneme is and which part of\\n00:10:04,500 --> 00:10:06,829\\nthe phoneme is it and a good speech\\n00:10:06,839 --> 00:10:08,840\\nrecognition system will have many\\n00:10:08,850 --> 00:10:10,249\\nalternative models for a phoneme and\\n00:10:10,259 --> 00:10:13,639\\neach model it might have three different\\n00:10:13,649 --> 00:10:15,199\\nparts so it might have many thousands of\\n00:10:15,209 --> 00:10:17,720\\nalternative fragments that it thinks\\n00:10:17,730 --> 00:10:19,400\\nthis might be and you have to place bets\\n00:10:19,410 --> 00:10:22,970\\non all those thousands of alternatives\\n00:10:22,980 --> 00:10:25,699\\nand then once you place those bets you\\n00:10:25,709 --> 00:10:29,840\\nhave a decoding stage that does the best\\n00:10:29,850 --> 00:10:32,900\\njob it can of using plausible bets but\\n00:10:32,910 --> 00:10:35,960\\npiecing them together into a sequence of\\n00:10:35,970 --> 00:10:40,819\\nbets that corresponds to the kinds of\\n00:10:40,829 --> 00:10:43,069\\nthings that people say currently deep\\n00:10:43,079 --> 00:10:45,350\\nneural networks pioneered by George Dahl\\n00:10:45,360 --> 00:10:47,660\\nand Abdul Rahman Muhammad of the\\n00:10:47,670 --> 00:10:49,670\\nUniversity of Toronto are doing better\\n00:10:49,680 --> 00:10:51,470\\nthan previous machine learning methods\\n00:10:51,480 --> 00:10:52,699\\nfor the acoustic model and they're now\\n00:10:52,709 --> 00:11:01,340\\nbeginning to be used in practical\\n00:11:01,350 --> 00:11:04,160\\nsystems so Darla Mohammed developed a\\n00:11:04,170 --> 00:11:10,430\\nsystem that uses many layers\\n00:11:10,440 --> 00:11:13,490\\nof binary neurons to take some acoustic\\n00:11:13,500 --> 00:11:15,470\\nframes and make bets about the labels\\n00:11:15,480 --> 00:11:17,960\\nthey were doing it on a fairly small\\n00:11:17,970 --> 00:11:20,210\\ndatabase and then used 183 alternative\\n00:11:20,220 --> 00:11:21,740\\nlengths and to get their system to work\\n00:11:21,750 --> 00:11:23,389\\nwell they did some pre training which\\n00:11:23,399 --> 00:11:26,540\\nwill be described in the second half of\\n00:11:26,550 --> 00:11:27,319\\nthe course after standard post\\n00:11:27,329 --> 00:11:29,960\\nprocessing\\n00:11:29,970 --> 00:11:31,879\\nthey got twenty point seven percent\\n00:11:31,889 --> 00:11:33,769\\nerror rate on a very standard benchmark\\n00:11:33,779 --> 00:11:36,949\\nwhich is kind of like the N missed for\\n00:11:36,959 --> 00:11:38,840\\nspeech the best previous result on that\\n00:11:38,850 --> 00:11:40,759\\nbenchmark for speech independent\\n00:11:40,769 --> 00:11:43,819\\nrecognition was twenty four point four\\n00:11:43,829 --> 00:11:46,840\\npercent and a very experienced receipt\\n00:11:46,850 --> 00:11:48,829\\nspeech researcher at Microsoft Research\\n00:11:48,839 --> 00:11:51,199\\nrealized that that was a big enough\\n00:11:51,209 --> 00:11:52,579\\nimprovement that probably this would\\n00:11:52,589 --> 00:11:57,079\\nchange the way speech recognition\\n00:11:57,089 --> 00:12:00,220\\nsystems were done and indeed it has so\\n00:12:00,230 --> 00:12:03,069\\nif you look at recent results from\\n00:12:03,079 --> 00:12:05,780\\nseveral different leading speech groups\\n00:12:05,790 --> 00:12:08,329\\nMicrosoft showed that this kind of deep\\n00:12:08,339 --> 00:12:10,699\\nneural network when used as the acoustic\\n00:12:10,709 --> 00:12:12,170\\nmodel in a speech system reduce the\\n00:12:12,180 --> 00:12:13,579\\nerror rate from thirty seven point four\\n00:12:13,589 --> 00:12:16,460\\npercent to eighteen point five percent\\n00:12:16,470 --> 00:12:18,110\\nor alternatively you could view it as\\n00:12:18,120 --> 00:12:20,600\\nreducing the amount of training data you\\n00:12:20,610 --> 00:12:21,949\\nneeded from two thousand hours down to\\n00:12:21,959 --> 00:12:25,490\\nthree hundred nine hours to get\\n00:12:25,500 --> 00:12:29,019\\ncomparable performance IBM which has the\\n00:12:29,029 --> 00:12:32,269\\nbest system for one of the standard\\n00:12:32,279 --> 00:12:35,360\\nspeech recognition tasks for large with\\n00:12:35,370 --> 00:12:37,400\\nlibrary speech recognition showed that\\n00:12:37,410 --> 00:12:40,069\\neven it's very highly tuned system that\\n00:12:40,079 --> 00:12:42,949\\nwas getting 18.8% can be beaten by one\\n00:12:42,959 --> 00:12:45,050\\nof these deep neural networks and Google\\n00:12:45,060 --> 00:12:47,720\\nfairly recently trained to deep neural\\n00:12:47,730 --> 00:12:49,670\\nnetwork on a large amount of speech five\\n00:12:49,680 --> 00:12:51,439\\nthousand eight hundred hours that was\\n00:12:51,449 --> 00:12:54,590\\nstill much less than their trend they\\n00:12:54,600 --> 00:12:56,780\\nguess in mixture model on but even with\\n00:12:56,790 --> 00:12:59,329\\nmuch less data it did a lot better than\\n00:12:59,339 --> 00:13:01,370\\nthe technology they had performed so\\n00:13:01,380 --> 00:13:03,050\\nreduce the error rate from 16 percent to\\n00:13:03,060 --> 00:13:05,660\\ntwelve point three percent and the error\\n00:13:05,670 --> 00:13:08,870\\nrate is still falling and in the latest\\n00:13:08,880 --> 00:13:10,460\\nAndroid if you do voice search it's\\n00:13:10,470 --> 00:13:12,949\\nusing one of these deep neural networks\\n00:13:12,949 --> 00:13:12,959\\n\\n00:13:12,959 --> 00:13:15,380\\nrecognition I want you to create a chapters section for this Youtube video with the following format:\\nChapters:\\n<double digit:time stamp> - <Concise phrase of a major part of the video>\"}\n",
      "{'role': 'assistant', 'content': '0min - Neural Networks for Machine Learning\\n0min - What is Machine Learning?\\n1min - The Machine Learning Approach\\n2min - Some examples of tasks best solved by learning\\n3min - A standard example of machine learning\\n4min - It is very hard to say what makes a 2\\n5min - Beyond MNIST: The ImageNet task\\n6min - Some examples from an earlier version of the net\\n9min - The Speech Recognition Task\\n11min - Word error rates from MSR, IBM, & Google (Hinton et. al. IEEE Signal Processing Magazine, Nov 2012)'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "\n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "\n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "\n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "\n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDqEu6Vqb7b1",
    "outputId": "c0ec5151-aea5-4766-88da-bb03fcc14140"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No errors found\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Some helpful utilities\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ],
   "metadata": {
    "id": "qKMxN1Y3b7v2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QWFJcld4b7-8",
    "outputId": "dd219781-e326-44ef-d8b2-e0a61fdfefd2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 1603, 11270\n",
      "mean / median: 5636.573333333334, 5328.0\n",
      "p5 / p95: 3031.4, 8144.400000000001\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 15, 143\n",
      "mean / median: 61.56, 56.0\n",
      "p5 / p95: 23.200000000000003, 109.00000000000004\n",
      "\n",
      "58 examples may be over the 4096 token limit\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 5\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "total_tokens = n_epochs * n_billing_tokens_in_dataset\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{total_tokens} tokens\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTTgFd6zcyhd",
    "outputId": "3c0b923f-3e12-4998-c85b-e919f48bfa78"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset has ~289402 tokens that will be charged for during training\n",
      "By default, you'll train for 5 epochs on this dataset\n",
      "By default, you'll be charged for ~1447010 tokens\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_cost_for_fine_tunning(token_count):\n",
    "    return (0.0080*token_count)/1000"
   ],
   "metadata": {
    "id": "vZ573ygcc2w5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "calculate_cost_for_fine_tunning(total_tokens)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4fqPM_Rc5Jn",
    "outputId": "ea011c1b-cf50-4762-b460-383e0bb3d8a0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11.57608"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "with open('openapi_key.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Access the API key\n",
    "api_key = data['api_key']\n",
    "\n"
   ],
   "metadata": {
    "id": "f6mY3e2OoDLs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "openai.api_key = api_key"
   ],
   "metadata": {
    "id": "SjSa0XCpesiN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "openai.File.create(\n",
    "  file=open(\"./dataset_fine_tunning.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "jvOjoNZqc9WF",
    "outputId": "8a311862-d2ad-4e87-be4b-27122b76fb75"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-21-fdc282c47d57>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m openai.File.create(\n\u001B[0;32m----> 2\u001B[0;31m   \u001B[0mfile\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"./dataset_fine_tunning.jsonl\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m   \u001B[0mpurpose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'fine-tune'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m )\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './dataset_fine_tunning.jsonl'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "openai.File.list()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nnAAttEic-GC",
    "outputId": "e7d34be1-91cc-466b-f892-92f359b57129"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x790381e2c400> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"has_more\": false,\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-Gh9QjaWiSNkcVGMpQnUVIgfR\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"file\",\n",
       "      \"bytes\": 1172965,\n",
       "      \"created_at\": 1699904999,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-Gte7mAIz441V3cXzg8TCMuob\",\n",
       "      \"purpose\": \"fine-tune-results\",\n",
       "      \"filename\": \"step_metrics.csv\",\n",
       "      \"bytes\": 52969,\n",
       "      \"created_at\": 1699817871,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-us4g6wbX61NcwnTkDyaDqdKS\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699817096,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-uDAtT547HDymTmUCcX6Q5pYh\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699817004,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-UEnadPUQvMFVA3oBgAae9k6o\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699816849,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-l5i3jVx1NZH839Cs1qEc4IpN\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699816827,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-lfTwMa51grh8AvoS4RTjgZ7k\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699816771,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-153nhiH3cQmKuLO8QkRrSnfS\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699816741,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-7EvUki5qKgUQCDZRjVBcziZY\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699816706,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-QUYpEbL3jXTZbCS0Kvcs0RXx\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699816642,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-UwhOSWgZf9FmKA1naYR3SyzO\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699816631,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-vWKXcCDW8rSSckp0IdUCLTz4\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699816608,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-A9J6ub6lhHfJQeupQDxxQdIw\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699816506,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-VawUvDTQIUMJv2ggIr78p17K\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699816383,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-sDjGUQ2maMkod5ub5eowc6t2\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699816339,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-pC1bVh1trsIX5zfJASKYQPWD\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"chat_reports.jsonl\",\n",
       "      \"bytes\": 1223848,\n",
       "      \"created_at\": 1699816291,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-TvuE3bhyzpqgoS9Ye9rruwNZ\",\n",
       "      \"purpose\": \"fine-tune-results\",\n",
       "      \"filename\": \"step_metrics.csv\",\n",
       "      \"bytes\": 33943,\n",
       "      \"created_at\": 1699815723,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-tS1bGyOj24FhtnyeukUl39tD\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"file\",\n",
       "      \"bytes\": 3048942,\n",
       "      \"created_at\": 1699812074,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-EvQKFFkvCfhpdAArLn5BGlAp\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"data.jsonl\",\n",
       "      \"bytes\": 3048942,\n",
       "      \"created_at\": 1699808992,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-qLq6jpwGl2LXablPnu6sr61m\",\n",
       "      \"purpose\": \"fine-tune-results\",\n",
       "      \"filename\": \"step_metrics.csv\",\n",
       "      \"bytes\": 3134,\n",
       "      \"created_at\": 1699775866,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-5ttcYlZ9tehhE4q3nx0aIukp\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"file\",\n",
       "      \"bytes\": 3208764,\n",
       "      \"created_at\": 1699774961,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "file_id = openai.File.list()[\"data\"][0][\"id\"]"
   ],
   "metadata": {
    "id": "gUmq6vZ0c-WW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "openai.FineTuningJob.create(training_file=file_id, model=\"gpt-3.5-turbo\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0qpaAd1uc-mT",
    "outputId": "5757f6c2-6cc9-46f7-9317-9e0f0e9a93a1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-REGHglifBfozrWIfiGsf6zBk at 0x790381e2ec50> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-REGHglifBfozrWIfiGsf6zBk\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1699905022,\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"organization_id\": \"org-0T52xTBIq1tVsEsgjkhEp7il\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"validating_files\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-Gh9QjaWiSNkcVGMpQnUVIgfR\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": \"auto\",\n",
       "    \"batch_size\": \"auto\",\n",
       "    \"learning_rate_multiplier\": \"auto\"\n",
       "  },\n",
       "  \"trained_tokens\": null,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# List 10 fine-tuning jobs\n",
    "openai.FineTuningJob.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "openai.FineTuningJob.retrieve(\"ftjob-REGHglifBfozrWIfiGsf6zBk\")\n",
    "\n",
    "# Cancel a job\n",
    "#openai.FineTuningJob.cancel(\"file-kXlvspUQRKFUWcrW5pgzy0PW\")\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "#openai.FineTuningJob.list_events(id=\"file-kXlvspUQRKFUWcrW5pgzy0PW\", limit=10)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVEly4oPc-38",
    "outputId": "7275d5ed-3997-4e15-bd1a-3dc2dd47e5ba"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-REGHglifBfozrWIfiGsf6zBk at 0x790381eb8f40> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-REGHglifBfozrWIfiGsf6zBk\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1699905022,\n",
       "  \"finished_at\": 1699905745,\n",
       "  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:leadsift::8KXQY7Yj\",\n",
       "  \"organization_id\": \"org-0T52xTBIq1tVsEsgjkhEp7il\",\n",
       "  \"result_files\": [\n",
       "    \"file-7wvC5iWYErSzMmWFDRunft4x\"\n",
       "  ],\n",
       "  \"status\": \"succeeded\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-Gh9QjaWiSNkcVGMpQnUVIgfR\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": 3,\n",
       "    \"batch_size\": 1,\n",
       "    \"learning_rate_multiplier\": 2\n",
       "  },\n",
       "  \"trained_tokens\": 868104,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference"
   ],
   "metadata": {
    "id": "b6t6iYpzlO8Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "inference_url = \"https://youtu.be/KWULpBYzIYk?si=Z4MQkyh7F3M7PmQi\""
   ],
   "metadata": {
    "id": "aip0r6Yhc_Nt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "c_filename, t_filename = get_youtube_chapters_and_transcript(inference_url)"
   ],
   "metadata": {
    "id": "nGt9KNtDmPLW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inferTranscription = load_transcription(\"/content/transcripts/#10 Machine Learning Specialization [Course 1, Week 1, Lesson 3] [KWULpBYzIYk].en.srt\")"
   ],
   "metadata": {
    "id": "G-FVmn2gnR2A"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inferTranscription"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "Y0xSBXCyqjH6",
    "outputId": "e47e6855-15dd-4b9c-b509-5747cd402e66"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"00:00:04,140 --> 00:00:06,889\\nlet's look in this video at the process\\n00:00:06,899 --> 00:00:08,810\\nof how supervised Learning Works\\n00:00:08,820 --> 00:00:11,089\\nsupervised learning algorithm will input\\n00:00:11,099 --> 00:00:13,430\\nthe data set and then what exactly does\\n00:00:13,440 --> 00:00:15,049\\nit do and what does it output let's find\\n00:00:15,059 --> 00:00:18,170\\nout in this video\\n00:00:18,180 --> 00:00:19,910\\nrecall that a training set in supervised\\n00:00:19,920 --> 00:00:21,769\\nlearning includes both the input\\n00:00:21,779 --> 00:00:24,769\\nfeatures such as the size of the house\\n00:00:24,779 --> 00:00:27,290\\nand also the output targets such as the\\n00:00:27,300 --> 00:00:29,450\\nprice of the house the output targets\\n00:00:29,460 --> 00:00:30,710\\nare the right answers to the model we'll\\n00:00:30,720 --> 00:00:33,410\\nlearn from\\n00:00:33,420 --> 00:00:35,690\\nto train the model you feed the trading\\n00:00:35,700 --> 00:00:38,270\\nset both the input features and the\\n00:00:38,280 --> 00:00:39,650\\noutput targets to your learning\\n00:00:39,660 --> 00:00:42,290\\nalgorithm\\n00:00:42,300 --> 00:00:44,869\\nthen your supervised learning algorithm\\n00:00:44,879 --> 00:00:47,389\\nwill produce some function\\n00:00:47,399 --> 00:00:50,930\\nwe'll write this function as lowercase f\\n00:00:50,940 --> 00:00:53,029\\nwhere F stands for function historically\\n00:00:53,039 --> 00:00:55,850\\nthis function used to be called a\\n00:00:55,860 --> 00:00:58,069\\nhypothesis but I'm just going to call it\\n00:00:58,079 --> 00:01:02,689\\na function f in this clause\\n00:01:02,699 --> 00:01:03,850\\nand the job of f is to take a new input\\n00:01:03,860 --> 00:01:08,230\\nX\\n00:01:08,240 --> 00:01:12,109\\nand upwards an estimate or prediction\\n00:01:12,119 --> 00:01:15,350\\nwhich I'm going to call Y hat and it's\\n00:01:15,360 --> 00:01:18,109\\nwritten like the variable y with this\\n00:01:18,119 --> 00:01:21,050\\nlittle hat symbol on top\\n00:01:21,060 --> 00:01:24,649\\nin machine learning the convention is\\n00:01:24,659 --> 00:01:27,770\\nthat y hat is the estimate or the\\n00:01:27,780 --> 00:01:31,550\\nprediction for y\\n00:01:31,560 --> 00:01:34,609\\nthe function f is called the model\\n00:01:34,619 --> 00:01:37,969\\nX is called the input or the input\\n00:01:37,979 --> 00:01:40,789\\nfeature and the output of the model is\\n00:01:40,799 --> 00:01:43,130\\nthe prediction y hat\\n00:01:43,140 --> 00:01:45,410\\nthe model's prediction is the estimated\\n00:01:45,420 --> 00:01:49,550\\nvalue of y\\n00:01:49,560 --> 00:01:52,370\\nwhen the symbol is just a letter Y then\\n00:01:52,380 --> 00:01:55,910\\nthat refers to the Target which is the\\n00:01:55,920 --> 00:01:58,969\\nactual True Value in the training set in\\n00:01:58,979 --> 00:02:02,030\\ncontrast y hat is an estimate it may or\\n00:02:02,040 --> 00:02:03,889\\nmay not be the actual True Value\\n00:02:03,899 --> 00:02:06,289\\nwell if you're helping your client to\\n00:02:06,299 --> 00:02:08,930\\nsell the house well the true price of\\n00:02:08,940 --> 00:02:12,650\\nthe house is unknown until they sell it\\n00:02:12,660 --> 00:02:14,690\\nso your model f given the size or\\n00:02:14,700 --> 00:02:17,330\\npressure price which is the estimated\\n00:02:17,340 --> 00:02:19,250\\nthat is the prediction of what the true\\n00:02:19,260 --> 00:02:23,030\\nprice will be\\n00:02:23,040 --> 00:02:26,030\\nnow when we design a learning algorithm\\n00:02:26,040 --> 00:02:29,030\\na key question is how are we going to\\n00:02:29,040 --> 00:02:31,850\\nrepresent the function f or in other\\n00:02:31,860 --> 00:02:35,270\\nwords what is the math formula we're\\n00:02:35,280 --> 00:02:38,449\\ngoing to use to compute f\\n00:02:38,459 --> 00:02:39,530\\nfor now let's stick with f being a\\n00:02:39,540 --> 00:02:42,710\\nstraight line\\n00:02:42,720 --> 00:02:47,750\\nso your function can be written as F\\n00:02:47,760 --> 00:02:52,009\\nsubscript W comma B of x equals I'm\\n00:02:52,019 --> 00:02:55,790\\ngoing to use W Times X plus b\\n00:02:55,800 --> 00:02:59,150\\nI'll Define w and B soon but for now\\n00:02:59,160 --> 00:03:02,270\\njust know that W and B are numbers and\\n00:03:02,280 --> 00:03:05,509\\nthe values chosen for w and B will\\n00:03:05,519 --> 00:03:10,970\\ndetermine the prediction y hat based on\\n00:03:10,980 --> 00:03:14,449\\nthe input feature X so this FWB of X\\n00:03:14,459 --> 00:03:17,449\\nmeans f is a function that takes X's\\n00:03:17,459 --> 00:03:21,229\\ninput and depending on the values of w\\n00:03:21,239 --> 00:03:23,809\\nand b f will output some value of a\\n00:03:23,819 --> 00:03:27,949\\nprediction y hat\\n00:03:27,959 --> 00:03:31,550\\nas an alternative to writing this FW\\n00:03:31,560 --> 00:03:34,490\\ncomma B of X I'll sometimes just write f\\n00:03:34,500 --> 00:03:36,410\\nof x without explicitly including W and\\n00:03:36,420 --> 00:03:39,170\\nB in the subscript it's just a simple\\n00:03:39,180 --> 00:03:42,890\\nnotation but means exactly the same\\n00:03:42,900 --> 00:03:45,170\\nthing as FWB of x\\n00:03:45,180 --> 00:03:47,630\\nlet's plot the trading set on the graph\\n00:03:47,640 --> 00:03:51,050\\nwhere the input feature X is on the\\n00:03:51,060 --> 00:03:55,130\\nhorizontal axis and the output targets Y\\n00:03:55,140 --> 00:03:57,470\\nis on the vertical axis remember the\\n00:03:57,480 --> 00:04:00,470\\nalbum learns from this data and\\n00:04:00,480 --> 00:04:02,149\\ngenerates a best fit line like maybe\\n00:04:02,159 --> 00:04:04,910\\nthis one here\\n00:04:04,920 --> 00:04:09,710\\nthis straight line is the linear\\n00:04:09,720 --> 00:04:11,750\\nfunction f w b of x equals W Times X\\n00:04:11,760 --> 00:04:16,009\\nplus b\\n00:04:16,019 --> 00:04:20,390\\nor more simply we can drop W and B and\\n00:04:20,400 --> 00:04:22,790\\njust write f of x equals WX plus b\\n00:04:22,800 --> 00:04:25,390\\nhere's what this function is doing is\\n00:04:25,400 --> 00:04:28,610\\nmaking predictions for the value of y\\n00:04:28,620 --> 00:04:31,490\\nusing a straight line function of x\\n00:04:31,500 --> 00:04:34,070\\nso you may ask why are we choosing a\\n00:04:34,080 --> 00:04:36,010\\nlinear function where linear function is\\n00:04:36,020 --> 00:04:38,930\\njust a fancy term for a straight line\\n00:04:38,940 --> 00:04:40,850\\ninstead of some nonlinear function like\\n00:04:40,860 --> 00:04:43,070\\na curve or a parabola\\n00:04:43,080 --> 00:04:45,230\\nwell sometimes you want to fit more\\n00:04:45,240 --> 00:04:48,350\\ncomplex non-linear functions as well\\n00:04:48,360 --> 00:04:50,749\\nlike a curve like this but since this\\n00:04:50,759 --> 00:04:53,510\\nlinear function is relatively simple and\\n00:04:53,520 --> 00:04:55,610\\neasy to work with let's use a line as a\\n00:04:55,620 --> 00:04:58,430\\nfoundation that will eventually help you\\n00:04:58,440 --> 00:05:00,050\\nto get to more complex models that are\\n00:05:00,060 --> 00:05:02,990\\nnon-linear\\n00:05:03,000 --> 00:05:05,090\\nthis particular model as a name is\\n00:05:05,100 --> 00:05:07,129\\ncalled linear regression more\\n00:05:07,139 --> 00:05:10,189\\nspecifically this is linear regression\\n00:05:10,199 --> 00:05:11,990\\nwith one variable with a phrase one\\n00:05:12,000 --> 00:05:15,290\\nvariable means that there's a single\\n00:05:15,300 --> 00:05:16,969\\ninput variable or feature X namely the\\n00:05:16,979 --> 00:05:20,210\\nsize of the host\\n00:05:20,220 --> 00:05:23,090\\nanother name for a linear model with one\\n00:05:23,100 --> 00:05:26,330\\ninput variable is univariate linear\\n00:05:26,340 --> 00:05:30,529\\nregression where uni means one in Latin\\n00:05:30,539 --> 00:05:32,570\\nand where variate means variable so univ\\n00:05:32,580 --> 00:05:34,430\\nvariance is just a fancy way of saying\\n00:05:34,440 --> 00:05:37,129\\none variable\\n00:05:37,139 --> 00:05:39,650\\nin a later video you also see a\\n00:05:39,660 --> 00:05:41,629\\nvariation of regression where you want\\n00:05:41,639 --> 00:05:43,969\\nto make a prediction based not just on\\n00:05:43,979 --> 00:05:46,010\\nthe size of a hose but on a bunch of\\n00:05:46,020 --> 00:05:47,749\\nother things that you may know about the\\n00:05:47,759 --> 00:05:50,210\\nwhole such as number of bedrooms and\\n00:05:50,220 --> 00:05:51,950\\nother features and by the way when\\n00:05:51,960 --> 00:05:54,590\\nyou're done with this video there is\\n00:05:54,600 --> 00:05:57,170\\nanother optional lab you don't need to\\n00:05:57,180 --> 00:05:59,390\\nwrite any code just review it run the\\n00:05:59,400 --> 00:06:02,029\\ncode and see what it does that will show\\n00:06:02,039 --> 00:06:04,909\\nyou how to define in Python a straight\\n00:06:04,919 --> 00:06:08,330\\nline function and the lab will let you\\n00:06:08,340 --> 00:06:10,129\\nchoose the values of wmb to try to fit\\n00:06:10,139 --> 00:06:12,350\\nthe training data\\n00:06:12,360 --> 00:06:14,270\\nyou don't have to do the lab if you\\n00:06:14,280 --> 00:06:16,969\\ndon't want to but I hope you play of it\\n00:06:16,979 --> 00:06:19,969\\nwhen you're done watching this video\\n00:06:19,979 --> 00:06:21,770\\nso that's linear regression in order for\\n00:06:21,780 --> 00:06:23,029\\nyou to make this work one of the most\\n00:06:23,039 --> 00:06:25,189\\nimportant things you have to do is\\n00:06:25,199 --> 00:06:27,230\\nconstruct a cost function\\n00:06:27,240 --> 00:06:29,570\\nthe idea of a cost function is one of\\n00:06:29,580 --> 00:06:32,450\\nthe most universal and important ideas\\n00:06:32,460 --> 00:06:34,909\\nin machine learning and is used in both\\n00:06:34,919 --> 00:06:36,950\\nlinear regression and in training many\\n00:06:36,960 --> 00:06:39,350\\nof the most advanced AI models in the\\n00:06:39,360 --> 00:06:41,689\\nworld so let's go on to the next video\\n00:06:41,689 --> 00:06:41,699\\n \\n00:06:41,699 --> 00:06:44,900\\na cost function\""
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 86
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "prompt = \"\"\"\n",
    "Given this Youtube video transcript:\n",
    "'''\n",
    "00:00:04,140 --> 00:00:06,889\n",
    "let's look in this video at the process\n",
    "00:00:06,899 --> 00:00:08,810\n",
    "of how supervised Learning Works\n",
    "00:00:08,820 --> 00:00:11,089\n",
    "supervised learning algorithm will input\n",
    "00:00:11,099 --> 00:00:13,430\n",
    "the data set and then what exactly does\n",
    "00:00:13,440 --> 00:00:15,049\n",
    "it do and what does it output let's find\n",
    "00:00:15,059 --> 00:00:18,170\n",
    "out in this video\n",
    "00:00:18,180 --> 00:00:19,910\n",
    "recall that a training set in supervised\n",
    "00:00:19,920 --> 00:00:21,769\n",
    "learning includes both the input\n",
    "00:00:21,779 --> 00:00:24,769\n",
    "features such as the size of the house\n",
    "00:00:24,779 --> 00:00:27,290\n",
    "and also the output targets such as the\n",
    "00:00:27,300 --> 00:00:29,450\n",
    "price of the house the output targets\n",
    "00:00:29,460 --> 00:00:30,710\n",
    "are the right answers to the model we'll\n",
    "00:00:30,720 --> 00:00:33,410\n",
    "learn from\n",
    "00:00:33,420 --> 00:00:35,690\n",
    "to train the model you feed the trading\n",
    "00:00:35,700 --> 00:00:38,270\n",
    "set both the input features and the\n",
    "00:00:38,280 --> 00:00:39,650\n",
    "output targets to your learning\n",
    "00:00:39,660 --> 00:00:42,290\n",
    "algorithm\n",
    "00:00:42,300 --> 00:00:44,869\n",
    "then your supervised learning algorithm\n",
    "00:00:44,879 --> 00:00:47,389\n",
    "will produce some function\n",
    "00:00:47,399 --> 00:00:50,930\n",
    "we'll write this function as lowercase f\n",
    "00:00:50,940 --> 00:00:53,029\n",
    "where F stands for function historically\n",
    "00:00:53,039 --> 00:00:55,850\n",
    "this function used to be called a\n",
    "00:00:55,860 --> 00:00:58,069\n",
    "hypothesis but I'm just going to call it\n",
    "00:00:58,079 --> 00:01:02,689\n",
    "a function f in this clause\n",
    "00:01:02,699 --> 00:01:03,850\n",
    "and the job of f is to take a new input\n",
    "00:01:03,860 --> 00:01:08,230\n",
    "X\n",
    "00:01:08,240 --> 00:01:12,109\n",
    "and upwards an estimate or prediction\n",
    "00:01:12,119 --> 00:01:15,350\n",
    "which I'm going to call Y hat and it's\n",
    "00:01:15,360 --> 00:01:18,109\n",
    "written like the variable y with this\n",
    "00:01:18,119 --> 00:01:21,050\n",
    "little hat symbol on top\n",
    "00:01:21,060 --> 00:01:24,649\n",
    "in machine learning the convention is\n",
    "00:01:24,659 --> 00:01:27,770\n",
    "that y hat is the estimate or the\n",
    "00:01:27,780 --> 00:01:31,550\n",
    "prediction for y\n",
    "00:01:31,560 --> 00:01:34,609\n",
    "the function f is called the model\n",
    "00:01:34,619 --> 00:01:37,969\n",
    "X is called the input or the input\n",
    "00:01:37,979 --> 00:01:40,789\n",
    "feature and the output of the model is\n",
    "00:01:40,799 --> 00:01:43,130\n",
    "the prediction y hat\n",
    "00:01:43,140 --> 00:01:45,410\n",
    "the model's prediction is the estimated\n",
    "00:01:45,420 --> 00:01:49,550\n",
    "value of y\n",
    "00:01:49,560 --> 00:01:52,370\n",
    "when the symbol is just a letter Y then\n",
    "00:01:52,380 --> 00:01:55,910\n",
    "that refers to the Target which is the\n",
    "00:01:55,920 --> 00:01:58,969\n",
    "actual True Value in the training set in\n",
    "00:01:58,979 --> 00:02:02,030\n",
    "contrast y hat is an estimate it may or\n",
    "00:02:02,040 --> 00:02:03,889\n",
    "may not be the actual True Value\n",
    "00:02:03,899 --> 00:02:06,289\n",
    "well if you're helping your client to\n",
    "00:02:06,299 --> 00:02:08,930\n",
    "sell the house well the true price of\n",
    "00:02:08,940 --> 00:02:12,650\n",
    "the house is unknown until they sell it\n",
    "00:02:12,660 --> 00:02:14,690\n",
    "so your model f given the size or\n",
    "00:02:14,700 --> 00:02:17,330\n",
    "pressure price which is the estimated\n",
    "00:02:17,340 --> 00:02:19,250\n",
    "that is the prediction of what the true\n",
    "00:02:19,260 --> 00:02:23,030\n",
    "price will be\n",
    "00:02:23,040 --> 00:02:26,030\n",
    "now when we design a learning algorithm\n",
    "00:02:26,040 --> 00:02:29,030\n",
    "a key question is how are we going to\n",
    "00:02:29,040 --> 00:02:31,850\n",
    "represent the function f or in other\n",
    "00:02:31,860 --> 00:02:35,270\n",
    "words what is the math formula we're\n",
    "00:02:35,280 --> 00:02:38,449\n",
    "going to use to compute f\n",
    "00:02:38,459 --> 00:02:39,530\n",
    "for now let's stick with f being a\n",
    "00:02:39,540 --> 00:02:42,710\n",
    "straight line\n",
    "00:02:42,720 --> 00:02:47,750\n",
    "so your function can be written as F\n",
    "00:02:47,760 --> 00:02:52,009\n",
    "subscript W comma B of x equals I'm\n",
    "00:02:52,019 --> 00:02:55,790\n",
    "going to use W Times X plus b\n",
    "00:02:55,800 --> 00:02:59,150\n",
    "I'll Define w and B soon but for now\n",
    "00:02:59,160 --> 00:03:02,270\n",
    "just know that W and B are numbers and\n",
    "00:03:02,280 --> 00:03:05,509\n",
    "the values chosen for w and B will\n",
    "00:03:05,519 --> 00:03:10,970\n",
    "determine the prediction y hat based on\n",
    "00:03:10,980 --> 00:03:14,449\n",
    "the input feature X so this FWB of X\n",
    "00:03:14,459 --> 00:03:17,449\n",
    "means f is a function that takes X's\n",
    "00:03:17,459 --> 00:03:21,229\n",
    "input and depending on the values of w\n",
    "00:03:21,239 --> 00:03:23,809\n",
    "and b f will output some value of a\n",
    "00:03:23,819 --> 00:03:27,949\n",
    "prediction y hat\n",
    "00:03:27,959 --> 00:03:31,550\n",
    "as an alternative to writing this FW\n",
    "00:03:31,560 --> 00:03:34,490\n",
    "comma B of X I'll sometimes just write f\n",
    "00:03:34,500 --> 00:03:36,410\n",
    "of x without explicitly including W and\n",
    "00:03:36,420 --> 00:03:39,170\n",
    "B in the subscript it's just a simple\n",
    "00:03:39,180 --> 00:03:42,890\n",
    "notation but means exactly the same\n",
    "00:03:42,900 --> 00:03:45,170\n",
    "thing as FWB of x\n",
    "00:03:45,180 --> 00:03:47,630\n",
    "let's plot the trading set on the graph\n",
    "00:03:47,640 --> 00:03:51,050\n",
    "where the input feature X is on the\n",
    "00:03:51,060 --> 00:03:55,130\n",
    "horizontal axis and the output targets Y\n",
    "00:03:55,140 --> 00:03:57,470\n",
    "is on the vertical axis remember the\n",
    "00:03:57,480 --> 00:04:00,470\n",
    "album learns from this data and\n",
    "00:04:00,480 --> 00:04:02,149\n",
    "generates a best fit line like maybe\n",
    "00:04:02,159 --> 00:04:04,910\n",
    "this one here\n",
    "00:04:04,920 --> 00:04:09,710\n",
    "this straight line is the linear\n",
    "00:04:09,720 --> 00:04:11,750\n",
    "function f w b of x equals W Times X\n",
    "00:04:11,760 --> 00:04:16,009\n",
    "plus b\n",
    "00:04:16,019 --> 00:04:20,390\n",
    "or more simply we can drop W and B and\n",
    "00:04:20,400 --> 00:04:22,790\n",
    "just write f of x equals WX plus b\n",
    "00:04:22,800 --> 00:04:25,390\n",
    "here's what this function is doing is\n",
    "00:04:25,400 --> 00:04:28,610\n",
    "making predictions for the value of y\n",
    "00:04:28,620 --> 00:04:31,490\n",
    "using a straight line function of x\n",
    "00:04:31,500 --> 00:04:34,070\n",
    "so you may ask why are we choosing a\n",
    "00:04:34,080 --> 00:04:36,010\n",
    "linear function where linear function is\n",
    "00:04:36,020 --> 00:04:38,930\n",
    "just a fancy term for a straight line\n",
    "00:04:38,940 --> 00:04:40,850\n",
    "instead of some nonlinear function like\n",
    "00:04:40,860 --> 00:04:43,070\n",
    "a curve or a parabola\n",
    "00:04:43,080 --> 00:04:45,230\n",
    "well sometimes you want to fit more\n",
    "00:04:45,240 --> 00:04:48,350\n",
    "complex non-linear functions as well\n",
    "00:04:48,360 --> 00:04:50,749\n",
    "like a curve like this but since this\n",
    "00:04:50,759 --> 00:04:53,510\n",
    "linear function is relatively simple and\n",
    "00:04:53,520 --> 00:04:55,610\n",
    "easy to work with let's use a line as a\n",
    "00:04:55,620 --> 00:04:58,430\n",
    "foundation that will eventually help you\n",
    "00:04:58,440 --> 00:05:00,050\n",
    "to get to more complex models that are\n",
    "00:05:00,060 --> 00:05:02,990\n",
    "non-linear\n",
    "00:05:03,000 --> 00:05:05,090\n",
    "this particular model as a name is\n",
    "00:05:05,100 --> 00:05:07,129\n",
    "called linear regression more\n",
    "00:05:07,139 --> 00:05:10,189\n",
    "specifically this is linear regression\n",
    "00:05:10,199 --> 00:05:11,990\n",
    "with one variable with a phrase one\n",
    "00:05:12,000 --> 00:05:15,290\n",
    "variable means that there's a single\n",
    "00:05:15,300 --> 00:05:16,969\n",
    "input variable or feature X namely the\n",
    "00:05:16,979 --> 00:05:20,210\n",
    "size of the host\n",
    "00:05:20,220 --> 00:05:23,090\n",
    "another name for a linear model with one\n",
    "00:05:23,100 --> 00:05:26,330\n",
    "input variable is univariate linear\n",
    "00:05:26,340 --> 00:05:30,529\n",
    "regression where uni means one in Latin\n",
    "00:05:30,539 --> 00:05:32,570\n",
    "and where variate means variable so univ\n",
    "00:05:32,580 --> 00:05:34,430\n",
    "variance is just a fancy way of saying\n",
    "00:05:34,440 --> 00:05:37,129\n",
    "one variable\n",
    "00:05:37,139 --> 00:05:39,650\n",
    "in a later video you also see a\n",
    "00:05:39,660 --> 00:05:41,629\n",
    "variation of regression where you want\n",
    "00:05:41,639 --> 00:05:43,969\n",
    "to make a prediction based not just on\n",
    "00:05:43,979 --> 00:05:46,010\n",
    "the size of a hose but on a bunch of\n",
    "00:05:46,020 --> 00:05:47,749\n",
    "other things that you may know about the\n",
    "00:05:47,759 --> 00:05:50,210\n",
    "whole such as number of bedrooms and\n",
    "00:05:50,220 --> 00:05:51,950\n",
    "other features and by the way when\n",
    "00:05:51,960 --> 00:05:54,590\n",
    "you're done with this video there is\n",
    "00:05:54,600 --> 00:05:57,170\n",
    "another optional lab you don't need to\n",
    "00:05:57,180 --> 00:05:59,390\n",
    "write any code just review it run the\n",
    "00:05:59,400 --> 00:06:02,029\n",
    "code and see what it does that will show\n",
    "00:06:02,039 --> 00:06:04,909\n",
    "you how to define in Python a straight\n",
    "00:06:04,919 --> 00:06:08,330\n",
    "line function and the lab will let you\n",
    "00:06:08,340 --> 00:06:10,129\n",
    "choose the values of wmb to try to fit\n",
    "00:06:10,139 --> 00:06:12,350\n",
    "the training data\n",
    "00:06:12,360 --> 00:06:14,270\n",
    "you don't have to do the lab if you\n",
    "00:06:14,280 --> 00:06:16,969\n",
    "don't want to but I hope you play of it\n",
    "00:06:16,979 --> 00:06:19,969\n",
    "when you're done watching this video\n",
    "00:06:19,979 --> 00:06:21,770\n",
    "so that's linear regression in order for\n",
    "00:06:21,780 --> 00:06:23,029\n",
    "you to make this work one of the most\n",
    "00:06:23,039 --> 00:06:25,189\n",
    "important things you have to do is\n",
    "00:06:25,199 --> 00:06:27,230\n",
    "construct a cost function\n",
    "00:06:27,240 --> 00:06:29,570\n",
    "the idea of a cost function is one of\n",
    "00:06:29,580 --> 00:06:32,450\n",
    "the most universal and important ideas\n",
    "00:06:32,460 --> 00:06:34,909\n",
    "in machine learning and is used in both\n",
    "00:06:34,919 --> 00:06:36,950\n",
    "linear regression and in training many\n",
    "00:06:36,960 --> 00:06:39,350\n",
    "of the most advanced AI models in the\n",
    "00:06:39,360 --> 00:06:41,689\n",
    "world so let's go on to the next video\n",
    "00:06:41,689 --> 00:06:41,699\n",
    "\n",
    "00:06:41,699 --> 00:06:44,900\n",
    "a cost function\n",
    "'''\n",
    "\n",
    "I want you to create chapters section for this Youtube video with the following format: Chapters:\\n< time stamp in min and seconds seperated by :> - <Concise phrase of a major part of the video>\n",
    "\"\"\"\n",
    "\n",
    "async def async_openai_request(prompt):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return await loop.run_in_executor(None, openai.ChatCompletion.create, {\n",
    "        \"model\": \"ft:gpt-3.5-turbo-0613:leadsift::8KXQY7Yj\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0613:leadsift::8KXQY7Yj\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seNlMBNzqjj6",
    "outputId": "5e8c709b-564a-4940-a83c-dba8f81be313"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"0min 0s - Introduction\\n0min 0s - What is supervised learning\\n1min 43s - The function f\\n3min 0s - Linear function\\n4min 25s - Linear regression\\n6min 6s - Cost function\"\n",
      "}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "fFafmbpJqj6a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "RCfFTYtVqkKf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "X98gUoZpqkXV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "OGlO_Kipqkob"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ljh6S71Sqk3f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Fj8-LrfWDHQs"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
